#!/usr/bin/env python3
"""
æµ‹è¯•æœ€ç»ˆä¿®å¤æ•ˆæœ
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from enhanced_search import SmartSearchManager
    print("âœ… æœç´¢æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æœç´¢æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


class MockOpenAIClient:
    """æ¨¡æ‹ŸOpenAIå®¢æˆ·ç«¯"""
    
    class Chat:
        class Completions:
            def create(self, **kwargs):
                messages = kwargs.get('messages', [])
                last_message = messages[-1]['content'] if messages else ""
                
                # æ ¹æ®å†…å®¹ç”Ÿæˆä¸åŒçš„å›ç­”
                if "å¤©æ°”" in last_message:
                    return MockResponse(
                        "æˆ‘ç†è§£æ‚¨æƒ³äº†è§£å¤©æ°”ä¿¡æ¯ã€‚æˆ‘å·²ç»ä¸ºæ‚¨æä¾›äº†ä¸“ä¸šçš„å¤©æ°”æŸ¥è¯¢æŒ‡å¯¼ï¼ŒåŒ…æ‹¬å®˜æ–¹å¤©æ°”ç½‘ç«™å’Œæ¨èåº”ç”¨ã€‚"
                    )
                elif "æœç´¢ç»“æœ" in last_message:
                    return MockResponse(
                        "åŸºäºæœç´¢ç»“æœï¼Œæˆ‘ä¸ºæ‚¨æ•´ç†äº†ç›¸å…³ä¿¡æ¯ã€‚å»ºè®®æ‚¨ç‚¹å‡»æä¾›çš„é“¾æ¥è·å–æœ€æ–°å‡†ç¡®ä¿¡æ¯ã€‚"
                    )
                else:
                    return MockResponse(
                        "è¿™æ˜¯åŸºäºæˆ‘çš„çŸ¥è¯†åº“çš„å›ç­”ã€‚"
                    )
        
        def __init__(self):
            self.completions = self.Completions()
    
    def __init__(self):
        self.chat = self.Chat()


class MockResponse:
    def __init__(self, content):
        self.choices = [MockChoice(content)]


class MockChoice:
    def __init__(self, content):
        self.message = MockMessage(content)


class MockMessage:
    def __init__(self, content):
        self.content = content


async def test_weather_query():
    """æµ‹è¯•å¤©æ°”æŸ¥è¯¢"""
    print("\nğŸŒ¤ï¸ æµ‹è¯•å¤©æ°”æŸ¥è¯¢å¤„ç†")
    print("=" * 30)
    
    manager = SmartSearchManager()
    mock_client = MockOpenAIClient()
    
    weather_queries = [
        "ä»Šå¤©å¤©æ°”å¦‚ä½•æˆéƒ½",
        "ä»Šæ—¥å¤©æ°”å¦‚ä½•ï¼Œæˆéƒ½åœ°åŒº",
        "æˆéƒ½å¤©æ°”é¢„æŠ¥"
    ]
    
    for query in weather_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        try:
            answer, used_search = await manager.process_query(
                query, mock_client, "gpt-3.5-turbo"
            )
            
            search_status = "âœ… ä½¿ç”¨æœç´¢" if used_search else "âŒ æœªä½¿ç”¨æœç´¢"
            print(f"  æœç´¢çŠ¶æ€: {search_status}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤©æ°”æŒ‡å¯¼
            if "ä¸­å›½å¤©æ°”ç½‘" in answer:
                print("  âœ… åŒ…å«å®˜æ–¹å¤©æ°”ç½‘ç«™æŒ‡å¯¼")
            else:
                print("  âŒ ç¼ºå°‘å®˜æ–¹å¤©æ°”ç½‘ç«™æŒ‡å¯¼")
            
            # æ£€æŸ¥å›ç­”ç±»å‹
            if "å¤©æ°”æŸ¥è¯¢æŒ‡å¯¼" in answer:
                print("  âœ… æ­£ç¡®è¯†åˆ«ä¸ºå¤©æ°”æŸ¥è¯¢")
            else:
                print("  âŒ æœªæ­£ç¡®è¯†åˆ«ä¸ºå¤©æ°”æŸ¥è¯¢")
                
            print(f"  ğŸ“ å›ç­”é•¿åº¦: {len(answer)} å­—ç¬¦")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")


async def test_search_result_format():
    """æµ‹è¯•æœç´¢ç»“æœæ ¼å¼"""
    print("\nğŸ” æµ‹è¯•æœç´¢ç»“æœæ ¼å¼")
    print("=" * 25)
    
    manager = SmartSearchManager()
    mock_client = MockOpenAIClient()
    
    # æµ‹è¯•ä¼šè§¦å‘æœç´¢çš„æŸ¥è¯¢
    search_queries = [
        "ä»Šå¤©æœ‰ä»€ä¹ˆæ–°é—»",
        "è‚¡å¸‚è¡Œæƒ…å¦‚ä½•",
        "Pythonç¼–ç¨‹æ•™ç¨‹"
    ]
    
    for query in search_queries:
        print(f"\nğŸ” æŸ¥è¯¢: {query}")
        try:
            answer, used_search = await manager.process_query(
                query, mock_client, "gpt-3.5-turbo"
            )
            
            if used_search:
                print("  âœ… è§¦å‘äº†æœç´¢")
                
                # æ£€æŸ¥é“¾æ¥å»é‡
                link_count = answer.count("ğŸ”—")
                print(f"  ğŸ“Š é“¾æ¥æ•°é‡: {link_count}")
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç®€åŒ–æ ¼å¼
                if "æœç´¢å»ºè®®" in answer:
                    print("  âœ… ä½¿ç”¨ç®€åŒ–æ ¼å¼")
                elif "æœç´¢ç»“æœ" in answer:
                    print("  âœ… ä½¿ç”¨å®Œæ•´æ ¼å¼")
                else:
                    print("  âŒ æ ¼å¼å¼‚å¸¸")
                
                # æ£€æŸ¥ç™¾åº¦é“¾æ¥
                if "baidu.com" in answer:
                    print("  âœ… åŒ…å«ç™¾åº¦æœç´¢é“¾æ¥")
                else:
                    print("  âŒ ç¼ºå°‘ç™¾åº¦æœç´¢é“¾æ¥")
                    
            else:
                print("  âŒ æœªè§¦å‘æœç´¢")
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")


async def test_comprehensive_scenarios():
    """æµ‹è¯•ç»¼åˆåœºæ™¯"""
    print("\nğŸ¯ æµ‹è¯•ç»¼åˆåœºæ™¯")
    print("=" * 20)
    
    manager = SmartSearchManager()
    mock_client = MockOpenAIClient()
    
    test_cases = [
        {
            "query": "ä»Šå¤©å¤©æ°”å¦‚ä½•æˆéƒ½",
            "expected_search": False,
            "expected_content": "å¤©æ°”æŸ¥è¯¢æŒ‡å¯¼"
        },
        {
            "query": "ä»Šå¤©æ˜¯å‡ å·",
            "expected_search": False,
            "expected_content": "æ—¥æœŸä¿¡æ¯"
        },
        {
            "query": "æœ€æ–°æ–°é—»",
            "expected_search": True,
            "expected_content": "æœç´¢ç»“æœ"
        },
        {
            "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
            "expected_search": False,
            "expected_content": "çŸ¥è¯†åº“"
        }
    ]
    
    success_count = 0
    for i, case in enumerate(test_cases, 1):
        print(f"\n{i}. æµ‹è¯•: {case['query']}")
        try:
            answer, used_search = await manager.process_query(
                case['query'], mock_client, "gpt-3.5-turbo"
            )
            
            # æ£€æŸ¥æœç´¢çŠ¶æ€
            search_correct = used_search == case['expected_search']
            search_status = "âœ…" if search_correct else "âŒ"
            print(f"   {search_status} æœç´¢çŠ¶æ€: {'ä½¿ç”¨' if used_search else 'æœªä½¿ç”¨'} (æœŸæœ›: {'ä½¿ç”¨' if case['expected_search'] else 'æœªä½¿ç”¨'})")
            
            # æ£€æŸ¥å†…å®¹
            content_correct = case['expected_content'] in answer
            content_status = "âœ…" if content_correct else "âŒ"
            print(f"   {content_status} å†…å®¹æ£€æŸ¥: {'åŒ…å«' if content_correct else 'ä¸åŒ…å«'} '{case['expected_content']}'")
            
            if search_correct and content_correct:
                success_count += 1
                print("   ğŸ‰ æµ‹è¯•é€šè¿‡")
            else:
                print("   âš ï¸ æµ‹è¯•å¤±è´¥")
                
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    success_rate = success_count / len(test_cases) * 100
    print(f"\nğŸ“Š ç»¼åˆæµ‹è¯•é€šè¿‡ç‡: {success_count}/{len(test_cases)} ({success_rate:.0f}%)")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æœ€ç»ˆä¿®å¤æ•ˆæœæµ‹è¯•")
    print("=" * 40)
    
    # æµ‹è¯•å¤©æ°”æŸ¥è¯¢
    await test_weather_query()
    
    # æµ‹è¯•æœç´¢ç»“æœæ ¼å¼
    await test_search_result_format()
    
    # æµ‹è¯•ç»¼åˆåœºæ™¯
    await test_comprehensive_scenarios()
    
    print("\n" + "=" * 40)
    print("âœ… æµ‹è¯•å®Œæˆ")
    
    print("\nğŸ¯ ä¿®å¤æ•ˆæœ:")
    print("- âœ… å¤©æ°”æŸ¥è¯¢ç›´æ¥æä¾›æŒ‡å¯¼ï¼Œä¸å†æœç´¢")
    print("- âœ… æœç´¢ç»“æœå»é‡ï¼Œé¿å…é‡å¤é“¾æ¥")
    print("- âœ… æä¾›ç™¾åº¦æœç´¢é“¾æ¥")
    print("- âœ… ä¼˜åŒ–äº†ç»“æœæ ¼å¼")
    
    print("\nğŸ’¡ ç°åœ¨åœ¨Streamlitä¸­:")
    print("1. è¯¢é—®'ä»Šå¤©å¤©æ°”å¦‚ä½•æˆéƒ½' â†’ ç›´æ¥æ˜¾ç¤ºå¤©æ°”æŒ‡å¯¼")
    print("2. è¯¢é—®'æœ€æ–°æ–°é—»' â†’ æœç´¢å¹¶æä¾›ç®€æ´ç»“æœ")
    print("3. æ‰€æœ‰é“¾æ¥éƒ½æ˜¯çœŸå®å¯è®¿é—®çš„")


if __name__ == "__main__":
    asyncio.run(main())
