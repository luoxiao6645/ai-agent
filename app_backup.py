# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å¤šæ¨¡æ€AI Agent - Streamlit Cloudç‰ˆæœ¬
ä¸“ä¸ºStreamlit Cloudç¯å¢ƒä¼˜åŒ–ï¼Œå†…ç½®æ‰€æœ‰å¿…è¦åŠŸèƒ½
"""
import os
import streamlit as st
from datetime import datetime
from typing import Optional, Tuple, Any
from openai import OpenAI


class APIClientManager:
    """APIå®¢æˆ·ç«¯ç®¡ç†å™¨"""

    @staticmethod
    def create_openai_client() -> Optional[Tuple[OpenAI, str]]:
        """åˆ›å»ºOpenAIå®¢æˆ·ç«¯"""
        try:
            # æ£€æŸ¥ç«å±±æ–¹èˆŸAPIå¯†é’¥
            ark_api_key = None
            if hasattr(st, 'secrets'):
                ark_api_key = st.secrets.get("ARK_API_KEY", None)
            if not ark_api_key:
                ark_api_key = os.getenv("ARK_API_KEY")

            if ark_api_key and ark_api_key not in ["your_volcano_engine_ark_api_key_here", ""]:
                # ä½¿ç”¨ç«å±±æ–¹èˆŸAPI
                base_url = os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
                model = os.getenv("ARK_MODEL", "ep-20250506230532-w7rdw")

                if hasattr(st, 'secrets'):
                    base_url = st.secrets.get("ARK_BASE_URL", base_url)
                    model = st.secrets.get("ARK_MODEL", model)

                client = OpenAI(
                    api_key=ark_api_key,
                    base_url=base_url
                )
                return client, model

            # æ£€æŸ¥OpenAI APIå¯†é’¥
            openai_api_key = None
            if hasattr(st, 'secrets'):
                openai_api_key = st.secrets.get("OPENAI_API_KEY", None)
            if not openai_api_key:
                openai_api_key = os.getenv("OPENAI_API_KEY")

            if openai_api_key and openai_api_key not in ["your_openai_api_key_here", ""]:
                # ä½¿ç”¨OpenAI API
                client = OpenAI(api_key=openai_api_key)
                model = "gpt-3.5-turbo"
                return client, model

            return None

        except Exception as e:
            st.error(f"åˆ›å»ºAPIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None

    @staticmethod
    def test_api_connection(client: OpenAI, model: str) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10,
                timeout=10
            )
            return True
        except Exception:
            return False


class StreamlitUIHelper:
    """Streamlit UIåŠ©æ‰‹"""

    @staticmethod
    def setup_page_config():
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="æ™ºèƒ½AIåŠ©æ‰‹",
            page_icon="ğŸ¤–",
            layout="wide",
            initial_sidebar_state="expanded"
        )

    @staticmethod
    def show_api_config_guide():
        """æ˜¾ç¤ºAPIé…ç½®æŒ‡å—"""
        st.markdown("""
        ### ğŸ”‘ APIå¯†é’¥é…ç½®æŒ‡å—

        è¯·é…ç½®ä»¥ä¸‹ä»»ä¸€APIå¯†é’¥ï¼š

        #### æ–¹æ³•1: ç«å±±æ–¹èˆŸAPI (æ¨è)
        1. è®¿é—® [ç«å±±æ–¹èˆŸæ§åˆ¶å°](https://console.volcengine.com/ark)
        2. åˆ›å»ºAPIå¯†é’¥
        3. åœ¨Streamlit Cloudçš„Secretsä¸­æ·»åŠ ï¼š
        ```toml
        ARK_API_KEY = "your_ark_api_key_here"
        ARK_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
        ARK_MODEL = "your_model_endpoint"
        ```

        #### æ–¹æ³•2: OpenAI API
        1. è®¿é—® [OpenAIå¹³å°](https://platform.openai.com/api-keys)
        2. åˆ›å»ºAPIå¯†é’¥
        3. åœ¨Streamlit Cloudçš„Secretsä¸­æ·»åŠ ï¼š
        ```toml
        OPENAI_API_KEY = "your_openai_api_key_here"
        ```
        """)

    @staticmethod
    def show_sidebar_info():
        """æ˜¾ç¤ºä¾§è¾¹æ ä¿¡æ¯"""
        with st.sidebar:
            st.markdown("### ğŸ¤– æ™ºèƒ½AIåŠ©æ‰‹")
            st.markdown("---")

            st.markdown("#### âœ¨ åŠŸèƒ½ç‰¹æ€§")
            st.markdown("""
            - ğŸ’¬ æ™ºèƒ½å¯¹è¯äº¤æµ
            - ğŸ“ æ–‡ä»¶å†…å®¹åˆ†æ
            - ğŸ” æ–‡æœ¬æ€»ç»“åˆ†æ
            - ğŸ¯ å¤šç§å¤„ç†æ¨¡å¼
            """)

            st.markdown("#### ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
            if 'chat_count' not in st.session_state:
                st.session_state.chat_count = 0
            st.metric("å¯¹è¯æ¬¡æ•°", st.session_state.chat_count)

            st.markdown("---")
            st.markdown("#### ğŸ’¡ ä½¿ç”¨æç¤º")
            st.markdown("""
            - ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯
            - ä¸Šä¼ æ–‡ä»¶è¿›è¡ŒAIåˆ†æ
            - æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
            """)


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""

    @staticmethod
    def show_file_info(uploaded_file):
        """æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯"""
        st.markdown("#### ğŸ“‹ æ–‡ä»¶ä¿¡æ¯")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("æ–‡ä»¶å", uploaded_file.name)
        with col2:
            st.metric("æ–‡ä»¶å¤§å°", f"{uploaded_file.size / 1024:.1f} KB")
        with col3:
            st.metric("æ–‡ä»¶ç±»å‹", uploaded_file.type)

    @staticmethod
    def process_text_file(content: str, client: OpenAI, model: str, action: str):
        """å¤„ç†æ–‡æœ¬æ–‡ä»¶"""
        try:
            with st.spinner(f"æ­£åœ¨{action}æ–‡ä»¶å†…å®¹..."):
                if action == "æ€»ç»“":
                    prompt = f"è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„ä¸»è¦è¦ç‚¹ï¼š\n\n{content[:4000]}"
                else:  # åˆ†æ
                    prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„ç»“æ„ã€ä¸»é¢˜å’Œå…³é”®ä¿¡æ¯ï¼š\n\n{content[:4000]}"

                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.7
                )

                result = response.choices[0].message.content

                st.markdown(f"#### ğŸ¯ {action}ç»“æœ")
                st.markdown(result)

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")


class ChatManager:
    """èŠå¤©ç®¡ç†å™¨"""

    @staticmethod
    def initialize_chat():
        """åˆå§‹åŒ–èŠå¤©"""
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "chat_count" not in st.session_state:
            st.session_state.chat_count = 0

    @staticmethod
    def show_welcome_message():
        """æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯"""
        if not st.session_state.messages:
            welcome_msg = """
            ğŸ‘‹ æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼

            æˆ‘å¯ä»¥å¸®æ‚¨ï¼š
            - ğŸ’¬ å›ç­”å„ç§é—®é¢˜
            - ğŸ“ æ–‡æœ¬åˆ†æå’Œæ€»ç»“
            - ğŸ” ä¿¡æ¯æŸ¥è¯¢å’Œè§£é‡Š
            - ğŸ’¡ åˆ›æ„å’Œå»ºè®®

            è¯·éšæ—¶å‘æˆ‘æé—®ï¼
            """
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

    @staticmethod
    def display_chat_history():
        """æ˜¾ç¤ºèŠå¤©å†å²"""
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    @staticmethod
    def process_user_input(client: OpenAI, model: str, prompt: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            try:
                with st.spinner("æ€è€ƒä¸­..."):
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": m["role"], "content": m["content"]}
                            for m in st.session_state.messages[-10:]  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                        ],
                        max_tokens=1500,
                        temperature=0.7,
                        stream=True
                    )

                    # æµå¼æ˜¾ç¤ºå›å¤
                    response_placeholder = st.empty()
                    full_response = ""

                    for chunk in response:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            response_placeholder.markdown(full_response + "â–Œ")

                    response_placeholder.markdown(full_response)

                # æ·»åŠ AIå›å¤åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                st.session_state.chat_count += 1

            except Exception as e:
                st.error(f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯: {e}"
                })

# é¡µé¢é…ç½®
StreamlitUIHelper.setup_page_config()


def init_streamlit_client():
    """åˆå§‹åŒ–Streamlit Cloudå®¢æˆ·ç«¯"""
    # ä½¿ç”¨é‡æ„åçš„APIå®¢æˆ·ç«¯ç®¡ç†å™¨
    result = APIClientManager.create_openai_client()

    if not result:
        st.error("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        StreamlitUIHelper.show_api_config_guide()
        return None

    client, model = result

    # æµ‹è¯•è¿æ¥
    if APIClientManager.test_api_connection(client, model):
        import os

        api_type = "ç«å±±æ–¹èˆŸAPI" if os.getenv("ARK_API_KEY") else "OpenAI API"
        st.success(f"âœ… {api_type}è¿æ¥æˆåŠŸ")
        return client, model
    else:
        api_type = "ç«å±±æ–¹èˆŸAPI" if os.getenv("ARK_API_KEY") else "OpenAI API"
        st.error(f"âŒ {api_type}è¿æ¥æµ‹è¯•å¤±è´¥")
        st.info("è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return None, None


def streamlit_chat_interface(client, model):
    """ä¼˜åŒ–çš„å¯¹è¯ç•Œé¢ - ä½¿ç”¨é‡æ„åçš„èŠå¤©ç®¡ç†å™¨"""
    # åˆå§‹åŒ–å¯¹è¯
    ChatManager.initialize_chat()

    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    ChatManager.show_welcome_message()

    # æ˜¾ç¤ºå¯¹è¯å†å²
    ChatManager.display_chat_history()

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        ChatManager.process_user_input(client, model, prompt)


def streamlit_file_interface(client, model):
    """ä¼˜åŒ–çš„æ–‡ä»¶å¤„ç†ç•Œé¢ - ä½¿ç”¨é‡æ„åçš„æ–‡ä»¶å¤„ç†å™¨"""
    st.markdown("""
    ### ğŸ“ æ–‡ä»¶å¤„ç†

    ä¸Šä¼ æ–‡ä»¶è®©AIå¸®æ‚¨åˆ†æå’Œå¤„ç†ï¼š
    - ğŸ“„ **æ–‡æœ¬æ–‡ä»¶**: æ€»ç»“ã€åˆ†æã€ç¿»è¯‘
    - ğŸ–¼ï¸ **å›¾ç‰‡æ–‡ä»¶**: æè¿°ã€åˆ†æå›¾ç‰‡å†…å®¹
    """)

    uploaded_file = st.file_uploader(
        "é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶",
        type=['txt', 'md', 'pdf', 'docx', 'jpg', 'jpeg', 'png', 'gif'],
        help="æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€PDFã€Wordç­‰æ ¼å¼"
    )

    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        FileProcessor.show_file_info(uploaded_file)

        # å¤„ç†æ–‡æœ¬æ–‡ä»¶
        if uploaded_file.type.startswith('text/') or uploaded_file.name.endswith('.md'):
            try:
                content = uploaded_file.read().decode('utf-8')

                # æ–‡ä»¶é¢„è§ˆ
                st.markdown("#### ğŸ‘€ æ–‡ä»¶é¢„è§ˆ")
                if len(content) > 1000:
                    st.text_area("å†…å®¹é¢„è§ˆ", content[:1000] + "...", height=150, disabled=True)
                    st.caption(f"æ˜¾ç¤ºå‰1000å­—ç¬¦ï¼Œæ€»é•¿åº¦: {len(content)}å­—ç¬¦")
                else:
                    st.text_area("æ–‡ä»¶å†…å®¹", content, height=150, disabled=True)

                # å¤„ç†é€‰é¡¹
                st.markdown("#### ğŸ”§ AIå¤„ç†é€‰é¡¹")
                col1, col2 = st.columns(2)

                with col1:
                    if st.button("ğŸ“ æ€»ç»“å†…å®¹", use_container_width=True):
                        FileProcessor.process_text_file(content, client, model, "æ€»ç»“")

                with col2:
                    if st.button("ğŸ” åˆ†æå†…å®¹", use_container_width=True):
                        FileProcessor.process_text_file(content, client, model, "åˆ†æ")

            except Exception as e:
                st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")

        # å¤„ç†å›¾ç‰‡æ–‡ä»¶
        elif uploaded_file.type.startswith('image/'):
            st.markdown("#### ğŸ‘€ å›¾ç‰‡é¢„è§ˆ")
            st.image(uploaded_file, caption=uploaded_file.name, use_column_width=True)

            st.markdown("#### ğŸ”§ AIå¤„ç†é€‰é¡¹")
            if st.button("ğŸ–¼ï¸ æè¿°å›¾ç‰‡", use_container_width=True):
                st.info("ğŸ–¼ï¸ å›¾ç‰‡åˆ†æåŠŸèƒ½éœ€è¦æ”¯æŒè§†è§‰çš„AIæ¨¡å‹ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒã€‚")
                st.markdown("**æ›¿ä»£æ–¹æ¡ˆ**: æ‚¨å¯ä»¥æè¿°å›¾ç‰‡å†…å®¹ï¼Œæˆ‘æ¥å¸®æ‚¨åˆ†æï¼")

        # å…¶ä»–æ–‡ä»¶ç±»å‹
        else:
            st.info("ğŸ“‹ æ–‡ä»¶å·²ä¸Šä¼ ï¼Œå½“å‰ç‰ˆæœ¬ä¸»è¦æ”¯æŒæ–‡æœ¬æ–‡ä»¶çš„AIåˆ†æ")


def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¤– æ™ºèƒ½å¤šæ¨¡æ€AI Agent")

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    result = init_streamlit_client()

    if not result or result[0] is None:
        st.stop()

    client, model = result

    # ä½¿ç”¨é‡æ„åçš„ä¾§è¾¹æ 
    StreamlitUIHelper.show_sidebar_info()

    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“ æ–‡ä»¶å¤„ç†"])

    with tab1:
        streamlit_chat_interface(client, model)

    with tab2:
        streamlit_file_interface(client, model)

if __name__ == "__main__":
    main()
