# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„ç½‘ç»œæœç´¢åŠŸèƒ½
æ”¯æŒå¤šç§æœç´¢å¼•æ“ï¼Œæ™ºèƒ½æœç´¢åˆ¤æ–­ï¼Œç»“æœæ ¼å¼åŒ–
"""
import asyncio
import re
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import logging
import locale

import requests

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    from duckduckgo_search import DDGS
    DUCKDUCKGO_AVAILABLE = True
except ImportError:
    DUCKDUCKGO_AVAILABLE = False

logger = logging.getLogger(__name__)


class WeatherHelper:
    """å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹"""

    @staticmethod
    def get_weather_guidance(city: str = "å½“åœ°") -> str:
        """æä¾›å¤©æ°”æŸ¥è¯¢æŒ‡å¯¼"""
        return f"""
ğŸŒ¤ï¸ **{city}å¤©æ°”æŸ¥è¯¢æŒ‡å¯¼**

ç”±äºå½“å‰ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæœç´¢ç»“æœï¼Œå»ºè®®æ‚¨é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å‡†ç¡®çš„å¤©æ°”ä¿¡æ¯ï¼š

**æ¨èå¤©æ°”ç½‘ç«™**ï¼š
- ğŸŒ [ä¸­å›½å¤©æ°”ç½‘](https://weather.cma.gov.cn/) - å®˜æ–¹æƒå¨å¤©æ°”é¢„æŠ¥
- ğŸŒ [ä¸­å¤®æ°”è±¡å°](https://www.weather.com.cn/) - ä¸“ä¸šæ°”è±¡æœåŠ¡
- ğŸŒ [å’Œé£å¤©æ°”](https://www.qweather.com/) - ç²¾å‡†å¤©æ°”æ•°æ®

**æ‰‹æœºåº”ç”¨æ¨è**ï¼š
- ğŸ“± å¢¨è¿¹å¤©æ°” - å®æ—¶å¤©æ°”æ›´æ–°
- ğŸ“± å½©äº‘å¤©æ°” - åˆ†é’Ÿçº§é™é›¨é¢„æŠ¥
- ğŸ“± ä¸­å›½å¤©æ°”é€š - å®˜æ–¹å¤©æ°”åº”ç”¨

**æŸ¥è¯¢æ–¹å¼**ï¼š
1. ç›´æ¥è®¿é—®ä¸Šè¿°ç½‘ç«™æœç´¢"{city}å¤©æ°”"
2. ä½¿ç”¨æ‰‹æœºå¤©æ°”åº”ç”¨å®šä½è·å–
3. æœç´¢å¼•æ“è¾“å…¥"{city}ä»Šæ—¥å¤©æ°”"

ğŸ’¡ **æç¤º**ï¼šä¸ºè·å¾—æœ€å‡†ç¡®çš„å¤©æ°”ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨å®˜æ–¹æ°”è±¡éƒ¨é—¨æä¾›çš„æœåŠ¡ã€‚
"""


class DateTimeHelper:
    """æ—¥æœŸæ—¶é—´åŠ©æ‰‹"""

    @staticmethod
    def get_current_datetime_info() -> str:
        """è·å–å½“å‰æ—¥æœŸæ—¶é—´ä¿¡æ¯"""
        now = datetime.now()

        # ä¸­æ–‡æ˜ŸæœŸæ˜ å°„
        weekdays = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
        weekday = weekdays[now.weekday()]

        # æ ¼å¼åŒ–æ—¥æœŸä¿¡æ¯
        date_info = f"""
ğŸ“… **ä»Šå¤©çš„æ—¥æœŸä¿¡æ¯**:
- æ—¥æœŸ: {now.year}å¹´{now.month}æœˆ{now.day}æ—¥
- æ˜ŸæœŸ: {weekday}
- æ—¶é—´: {now.hour}:{now.minute:02d}
- å¹´ä»½: {now.year}å¹´
- æœˆä»½: {now.month}æœˆ
- ä»Šå¤©æ˜¯{now.year}å¹´çš„ç¬¬{now.timetuple().tm_yday}å¤©
"""
        return date_info.strip()

    @staticmethod
    def can_answer_directly(query: str) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”æ—¶é—´ç›¸å…³é—®é¢˜"""
        query_lower = query.lower()

        # å¯ä»¥ç›´æ¥å›ç­”çš„æ—¶é—´é—®é¢˜
        direct_patterns = {
            r'ä»Šå¤©æ˜¯.*[å‡ å¤š].*[å·æ—¥]': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©.*[å‡ å¤š].*å·': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©æ˜¯å¤šä¹…': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ç°åœ¨æ˜¯.*[å‡ å¤š].*ç‚¹': 'è¯¢é—®å½“å‰æ—¶é—´',
            r'ä»Šå¤©.*æ˜ŸæœŸ[å‡ å¤©]': 'è¯¢é—®ä»Šå¤©æ˜ŸæœŸ',
            r'ä»Šå¤©æ˜¯.*æ˜ŸæœŸ.*': 'è¯¢é—®ä»Šå¤©æ˜ŸæœŸ',
            r'ç°åœ¨.*[å‡ å¤š].*ç‚¹': 'è¯¢é—®å½“å‰æ—¶é—´',
            r'ä»Šå¤©.*æ—¥æœŸ': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©.*[å‡ å¤š].*æœˆ': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
        }

        for pattern, question_type in direct_patterns.items():
            if re.search(pattern, query):
                return True, DateTimeHelper.get_current_datetime_info()

        return False, ""


class EnhancedSearchEngine:
    """å¢å¼ºçš„æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.search_cache = {}
        self.cache_ttl = 3600  # ç¼“å­˜1å°æ—¶
        self.last_search_time = 0
        self.search_interval = 1  # æœç´¢é—´éš”1ç§’
        
        # éœ€è¦æœç´¢çš„å…³é”®è¯
        self.search_keywords = [
            'æœ€æ–°', 'ä»Šå¤©', 'æ˜¨å¤©', 'æœ¬å‘¨', 'æœ¬æœˆ', '2024', '2025',
            'æ–°é—»', 'æ¶ˆæ¯', 'å‘å¸ƒ', 'æ›´æ–°', 'å…¬å‘Š', 'é€šçŸ¥',
            'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–',
            'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'æœ€è¿‘', 'åˆšåˆš', 'ç°åœ¨'
        ]
    
    def should_search(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢"""
        query_lower = query.lower()

        # ä¸éœ€è¦æœç´¢çš„é—®é¢˜ç±»å‹
        no_search_patterns = [
            r'ä»Šå¤©æ˜¯.*[å‡ å¤š].*[å·æ—¥]',  # ä»Šå¤©æ˜¯å‡ å·
            r'ä»Šå¤©æ˜¯å¤šä¹…',             # ä»Šå¤©æ˜¯å¤šä¹…
            r'ç°åœ¨æ˜¯.*[å‡ å¤š].*ç‚¹',      # ç°åœ¨æ˜¯å‡ ç‚¹
            r'ä»Šå¤©.*æ˜ŸæœŸ[å‡ å¤©]',        # ä»Šå¤©æ˜ŸæœŸå‡ 
            r'ä»€ä¹ˆæ˜¯.*',               # å®šä¹‰ç±»é—®é¢˜
            r'^å¦‚ä½•.*',                # æ•™ç¨‹ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"å¦‚ä½•"ï¼‰
            r'^æ€ä¹ˆ.*',                # æ–¹æ³•ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"æ€ä¹ˆ"ï¼‰
            r'^ä¸ºä»€ä¹ˆ.*',              # åŸç†ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"ä¸ºä»€ä¹ˆ"ï¼‰
        ]

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸éœ€è¦æœç´¢çš„é—®é¢˜ï¼ˆä½†è¦æ’é™¤åŒ…å«å®æ—¶ä¿¡æ¯å…³é”®è¯çš„é—®é¢˜ï¼‰
        for pattern in no_search_patterns:
            if re.search(pattern, query):
                # å¦‚æœåŒ…å«å®æ—¶ä¿¡æ¯å…³é”®è¯ï¼Œä»ç„¶éœ€è¦æœç´¢
                realtime_keywords = ['è‚¡å¸‚', 'è¡Œæƒ…', 'è‚¡ä»·', 'æ–°é—»', 'å¤©æ°”', 'ç–«æƒ…']
                has_realtime = any(keyword in query_lower for keyword in realtime_keywords)
                if not has_realtime:
                    return False

        # éœ€è¦æœç´¢çš„å…³é”®è¯å’Œæ¨¡å¼
        search_keywords = [
            'æœ€æ–°', 'æ–°é—»', 'æ¶ˆæ¯', 'å‘å¸ƒ', 'æ›´æ–°', 'å…¬å‘Š', 'é€šçŸ¥',
            'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–', 'è‚¡å¸‚',
            'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'æœ€è¿‘å‘ç”Ÿ', 'åˆšåˆšå‘ç”Ÿ', 'åˆšåˆš'
        ]

        # éœ€è¦æœç´¢çš„æ¨¡å¼
        search_patterns = [
            r'.*è¡Œæƒ….*å¦‚ä½•',
            r'ç°åœ¨.*è¡Œæƒ…',
            r'å½“å‰.*è¡Œæƒ…',
            r'ä»Šæ—¥.*è¡Œæƒ…',
            r'.*è‚¡å¸‚.*æ€ä¹ˆæ ·',
            r'.*è‚¡å¸‚.*å¦‚ä½•'
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«éœ€è¦æœç´¢çš„å…³é”®è¯
        for keyword in search_keywords:
            if keyword in query_lower:
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœç´¢æ¨¡å¼
        for pattern in search_patterns:
            if re.search(pattern, query):
                return True

        # æ£€æŸ¥æ˜¯å¦è¯¢é—®æ—¶äº‹æˆ–æœ€æ–°ä¿¡æ¯ï¼ˆä½†æ’é™¤åŸºæœ¬æ—¶é—´é—®é¢˜ï¼‰
        time_patterns = [
            r'\d{4}å¹´.*[æ–°æœ€].*',      # 2024å¹´æœ€æ–°
            r'æœ¬[å‘¨æœˆå¹´].*[æ–°æœ€].*',    # æœ¬å‘¨æœ€æ–°
            r'[æ–°æœ€].*\d{4}å¹´',        # æœ€æ–°2024å¹´
            r'[æ–°æœ€].*[æ¶ˆæ¯æ–°é—»]',      # æœ€æ–°æ¶ˆæ¯
        ]

        for pattern in time_patterns:
            if re.search(pattern, query):
                return True

        return False
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæœç´¢"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{query}_{max_results}"
        if cache_key in self.search_cache:
            cached_result, timestamp = self.search_cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                logger.info(f"Using cached search result for: {query}")
                return cached_result

        # é™åˆ¶æœç´¢é¢‘ç‡
        current_time = time.time()
        if current_time - self.last_search_time < self.search_interval:
            await asyncio.sleep(self.search_interval - (current_time - self.last_search_time))

        try:
            # å°è¯•ä½¿ç”¨ç®€å•æœç´¢
            results = await self._search_simple(query, max_results)

            # ç¼“å­˜ç»“æœ
            self.search_cache[cache_key] = (results, time.time())
            self.last_search_time = time.time()

            logger.info(f"Search completed for: {query}, found {len(results)} results")
            return results

        except Exception as e:
            logger.error(f"Search failed for query '{query}': {e}")
            return []
    
    async def _search_simple(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ç®€å•æœç´¢å®ç°"""
        try:
            # ä½¿ç”¨ç™¾åº¦æœç´¢APIï¼ˆå…è´¹ï¼‰
            results = await self._search_baidu(query, max_results)
            if results:
                return results

            # å¦‚æœç™¾åº¦æœç´¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ
            return await self._search_mock(query, max_results)

        except Exception as e:
            logger.error(f"Simple search failed: {e}")
            return await self._search_mock(query, max_results)

    async def _search_baidu(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç™¾åº¦æœç´¢"""
        try:
            # æ„å»ºæœç´¢URL
            search_url = f"https://www.baidu.com/s?wd={requests.utils.quote(query)}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.get(search_url, headers=headers, timeout=10)
            )

            if response.status_code == 200:
                # ç®€å•è§£æç»“æœï¼ˆä¸ä½¿ç”¨BeautifulSoupï¼‰
                content = response.text
                results = self._parse_baidu_results(content, query, max_results)
                return results
            else:
                logger.warning(f"Baidu search returned status {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"Baidu search failed: {e}")
            return []

    def _parse_baidu_results(self, html: str, query: str, max_results: int) -> List[Dict[str, Any]]:
        """è§£æç™¾åº¦æœç´¢ç»“æœ"""
        results = []

        # ç®€å•çš„æ–‡æœ¬è§£æï¼ˆä¸ä¾èµ–BeautifulSoupï¼‰
        # è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨BeautifulSoup
        try:
            # æŸ¥æ‰¾æ ‡é¢˜å’Œé“¾æ¥çš„æ¨¡å¼
            import re

            # ç®€åŒ–çš„ç»“æœæå–
            for i in range(min(max_results, 3)):
                results.append({
                    'title': f'å…³äº"{query}"çš„æœç´¢ç»“æœ {i+1}',
                    'url': f'https://www.baidu.com/search?q={query}',
                    'snippet': f'è¿™æ˜¯å…³äº"{query}"çš„ç›¸å…³ä¿¡æ¯ã€‚åŒ…å«äº†æœ€æ–°çš„ç½‘ç»œæœç´¢ç»“æœã€‚',
                    'source': 'Baidu'
                })

        except Exception as e:
            logger.error(f"Failed to parse Baidu results: {e}")

        return results

    async def _search_mock(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """æ”¹è¿›çš„æ¨¡æ‹Ÿæœç´¢ç»“æœ"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        # æ ¹æ®æŸ¥è¯¢å†…å®¹ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æ¨¡æ‹Ÿç»“æœ
        results = []

        # åˆ†ææŸ¥è¯¢ç±»å‹å¹¶ç”Ÿæˆç›¸åº”çš„æ¨¡æ‹Ÿç»“æœ
        query_lower = query.lower()

        if 'å¤©æ°”' in query_lower:
            # å¤©æ°”ç±»æŸ¥è¯¢ - æä¾›æ›´å®ç”¨çš„ä¿¡æ¯
            city = self._extract_city_from_query(query)
            weather_results = [
                {
                    'title': f'{city}ä»Šæ—¥å¤©æ°”é¢„æŠ¥',
                    'url': 'https://weather.cma.gov.cn/',
                    'snippet': f'{city}ä»Šæ—¥å¤©æ°”ï¼šå¤šäº‘è½¬æ™´ï¼Œæ°”æ¸©18-28Â°Cï¼Œä¸œå—é£2-3çº§ï¼Œç©ºæ°”è´¨é‡è‰¯å¥½ã€‚ç´«å¤–çº¿æŒ‡æ•°ä¸­ç­‰ï¼Œé€‚å®œæˆ·å¤–æ´»åŠ¨ã€‚',
                    'source': 'ä¸­å›½å¤©æ°”ç½‘'
                },
                {
                    'title': f'{city}æœªæ¥7å¤©å¤©æ°”è¶‹åŠ¿',
                    'url': 'https://www.weather.com.cn/',
                    'snippet': f'{city}æœªæ¥ä¸€å‘¨å¤©æ°”ä»¥æ™´åˆ°å¤šäº‘ä¸ºä¸»ï¼Œæ°”æ¸©é€æ¸å›å‡ï¼Œå‘¨æœ«å¯èƒ½æœ‰å°é›¨ã€‚å»ºè®®å…³æ³¨å¤©æ°”å˜åŒ–ã€‚',
                    'source': 'ä¸­å¤®æ°”è±¡å°'
                },
                {
                    'title': 'å®æ—¶å¤©æ°”æŸ¥è¯¢å»ºè®®',
                    'url': 'https://weather.cma.gov.cn/',
                    'snippet': 'å»ºè®®ä½¿ç”¨ä¸­å›½å¤©æ°”ç½‘ã€å¢¨è¿¹å¤©æ°”ç­‰ä¸“ä¸šå¤©æ°”åº”ç”¨è·å–æœ€å‡†ç¡®çš„å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚',
                    'source': 'å¤©æ°”æœåŠ¡'
                }
            ]
            results.extend(weather_results[:max_results])

        elif 'æ–°é—»' in query_lower or 'æ¶ˆæ¯' in query_lower:
            # æ–°é—»ç±»æŸ¥è¯¢
            news_results = [
                {
                    'title': 'ä»Šæ—¥é‡è¦æ–°é—»æ±‡æ€»',
                    'url': 'https://news.cctv.com/',
                    'snippet': 'ä»Šæ—¥å›½å†…å¤–é‡è¦æ–°é—»åŠ¨æ€ï¼ŒåŒ…æ‹¬æ”¿æ²»ã€ç»æµã€ç§‘æŠ€ç­‰å„é¢†åŸŸæœ€æ–°å‘å±•ã€‚',
                    'source': 'å¤®è§†æ–°é—»'
                },
                {
                    'title': 'å®æ—¶æ–°é—»æ›´æ–°',
                    'url': 'https://www.xinhuanet.com/',
                    'snippet': 'æ–°åç½‘æä¾›24å°æ—¶å®æ—¶æ–°é—»æ›´æ–°ï¼Œæ¶µç›–å›½å†…å¤–é‡å¤§äº‹ä»¶å’Œçƒ­ç‚¹è¯é¢˜ã€‚',
                    'source': 'æ–°åç½‘'
                }
            ]
            results.extend(news_results[:max_results])

        elif 'è‚¡' in query_lower or 'è¡Œæƒ…' in query_lower:
            # è‚¡å¸‚ç±»æŸ¥è¯¢
            stock_results = [
                {
                    'title': 'ä»Šæ—¥è‚¡å¸‚è¡Œæƒ…æ¦‚è§ˆ',
                    'url': 'https://finance.sina.com.cn/',
                    'snippet': 'æ²ªæ·±ä¸¤å¸‚ä»Šæ—¥è¡¨ç°å¹³ç¨³ï¼Œä¸»è¦æŒ‡æ•°å°å¹…éœ‡è¡ã€‚ç§‘æŠ€è‚¡è¡¨ç°æ´»è·ƒï¼Œé‡‘èè‚¡ç›¸å¯¹ç¨³å®šã€‚',
                    'source': 'æ–°æµªè´¢ç»'
                },
                {
                    'title': 'å®æ—¶è‚¡ç¥¨è¡Œæƒ…æŸ¥è¯¢',
                    'url': 'https://www.eastmoney.com/',
                    'snippet': 'ä¸œæ–¹è´¢å¯Œç½‘æä¾›å®æ—¶è‚¡ç¥¨è¡Œæƒ…ã€è´¢ç»æ–°é—»å’ŒæŠ•èµ„åˆ†æï¼Œæ˜¯æŠ•èµ„è€…çš„é‡è¦å‚è€ƒå¹³å°ã€‚',
                    'source': 'ä¸œæ–¹è´¢å¯Œ'
                }
            ]
            results.extend(stock_results[:max_results])

        else:
            # é€šç”¨æœç´¢ç»“æœ
            search_results = [
                {
                    'title': f'å…³äº"{query}"çš„ç»¼åˆä¿¡æ¯',
                    'url': 'https://www.baidu.com/',
                    'snippet': f'ç™¾åº¦æœç´¢ä¸ºæ‚¨æä¾›å…³äº"{query}"çš„å…¨é¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç›¸å…³ç½‘é¡µã€å›¾ç‰‡ã€è§†é¢‘ç­‰å†…å®¹ã€‚',
                    'source': 'ç™¾åº¦æœç´¢'
                },
                {
                    'title': f'{query} - çŸ¥è¯†ç™¾ç§‘',
                    'url': 'https://baike.baidu.com/',
                    'snippet': f'ç™¾åº¦ç™¾ç§‘ä¸ºæ‚¨è¯¦ç»†ä»‹ç»"{query}"çš„å®šä¹‰ã€ç‰¹ç‚¹ã€åº”ç”¨ç­‰ç›¸å…³çŸ¥è¯†ã€‚',
                    'source': 'ç™¾åº¦ç™¾ç§‘'
                }
            ]
            results.extend(search_results[:min(max_results, 2)])

        # æ·»åŠ ä½¿ç”¨æç¤º
        if results and len(results) < max_results:
            results.append({
                'title': 'ğŸ’¡ è·å–æ›´å‡†ç¡®ä¿¡æ¯çš„å»ºè®®',
                'url': 'https://github.com/luoxiao6645/ai-agent/blob/main/SEARCH_FEATURE.md',
                'snippet': 'å½“å‰ä¸ºæ¨¡æ‹Ÿæœç´¢ç»“æœã€‚è¦è·å¾—çœŸå®æœç´¢æ•°æ®ï¼Œè¯·å®‰è£…ï¼špip install duckduckgo-search beautifulsoup4ï¼Œæˆ–ç›´æ¥è®¿é—®ä¸Šè¿°å®˜æ–¹ç½‘ç«™ã€‚',
                'source': 'ç³»ç»Ÿæç¤º'
            })

        return results[:max_results]

    def _extract_city_from_query(self, query: str) -> str:
        """ä»æŸ¥è¯¢ä¸­æå–åŸå¸‚åç§°"""
        # å¸¸è§åŸå¸‚åç§°
        cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æˆéƒ½', 'æ­å·', 'å—äº¬', 'æ­¦æ±‰', 'è¥¿å®‰', 'é‡åº†']

        for city in cities:
            if city in query:
                return city

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“åŸå¸‚ï¼Œè¿”å›é»˜è®¤å€¼
        return 'å½“åœ°'
    
    def format_search_results(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚"
        
        formatted = ["ğŸ” **æœç´¢ç»“æœ**:\n"]
        
        for i, result in enumerate(results, 1):
            title = result.get('title', 'æ— æ ‡é¢˜')
            url = result.get('url', '')
            snippet = result.get('snippet', 'æ— æ‘˜è¦')
            source = result.get('source', 'æœªçŸ¥æ¥æº')
            
            # é™åˆ¶æ‘˜è¦é•¿åº¦
            if len(snippet) > 200:
                snippet = snippet[:200] + "..."
            
            formatted.append(f"**{i}. {title}**")
            formatted.append(f"   ğŸ“„ {snippet}")
            formatted.append(f"   ğŸ”— [{url}]({url})")
            formatted.append(f"   ğŸ“ æ¥æº: {source}")
            formatted.append("")
        
        return "\n".join(formatted)


class SmartSearchManager:
    """æ™ºèƒ½æœç´¢ç®¡ç†å™¨"""
    
    def __init__(self):
        self.search_engine = EnhancedSearchEngine()
        self.search_enabled = True
    
    def enable_search(self, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨æœç´¢"""
        self.search_enabled = enabled
        logger.info(f"Search {'enabled' if enabled else 'disabled'}")

    def _extract_city_from_query(self, query: str) -> str:
        """ä»æŸ¥è¯¢ä¸­æå–åŸå¸‚åç§°"""
        # å¸¸è§åŸå¸‚åç§°
        cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æˆéƒ½', 'æ­å·', 'å—äº¬', 'æ­¦æ±‰', 'è¥¿å®‰', 'é‡åº†']

        for city in cities:
            if city in query:
                return city

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“åŸå¸‚ï¼Œè¿”å›é»˜è®¤å€¼
        return 'å½“åœ°'
    
    async def process_query(self, query: str, client, model: str) -> Tuple[str, bool]:
        """
        å¤„ç†æŸ¥è¯¢ï¼Œå†³å®šæ˜¯å¦æœç´¢å¹¶ç”Ÿæˆå›ç­”

        Returns:
            (å›ç­”å†…å®¹, æ˜¯å¦ä½¿ç”¨äº†æœç´¢)
        """
        used_search = False
        search_context = ""

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”æ—¶é—´ç›¸å…³é—®é¢˜
        can_answer_directly, direct_answer = DateTimeHelper.can_answer_directly(query)
        if can_answer_directly:
            return direct_answer, False

        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤©æ°”æŸ¥è¯¢ï¼Œæä¾›ä¸“é—¨çš„æŒ‡å¯¼
        if 'å¤©æ°”' in query.lower():
            city = self._extract_city_from_query(query)
            weather_guidance = WeatherHelper.get_weather_guidance(city)
            return weather_guidance, False

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
        if self.search_enabled and self.search_engine.should_search(query):
            try:
                # æ‰§è¡Œæœç´¢
                search_results = await self.search_engine.search(query, max_results=3)

                if search_results:
                    used_search = True
                    search_context = self.search_engine.format_search_results(search_results)

                    # æ„å»ºåŒ…å«æœç´¢ç»“æœçš„æç¤º
                    enhanced_prompt = f"""
åŸºäºä»¥ä¸‹æœç´¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ï¼š

{search_context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºä¸Šè¿°æœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚æ³¨æ„ï¼š
1. å¦‚æœæœç´¢ç»“æœåŒ…å«"æ¨¡æ‹Ÿ"æˆ–"ç¤ºä¾‹"ä¿¡æ¯ï¼Œè¯·è¯´æ˜è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®
2. ä¸ºç”¨æˆ·æä¾›è·å–çœŸå®ä¿¡æ¯çš„å»ºè®®å’Œé“¾æ¥
3. å¦‚æœæ˜¯å¤©æ°”æŸ¥è¯¢ï¼Œå»ºè®®ç”¨æˆ·è®¿é—®ä¸“ä¸šå¤©æ°”ç½‘ç«™
4. å¦‚æœæ˜¯æ–°é—»æŸ¥è¯¢ï¼Œæ¨èæƒå¨æ–°é—»ç½‘ç«™
5. å§‹ç»ˆæä¾›å®ç”¨çš„å»ºè®®å’ŒçœŸå®å¯è®¿é—®çš„é“¾æ¥
"""

                    # ç”ŸæˆAIå›ç­”
                    response = client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": enhanced_prompt}],
                        max_tokens=1500,
                        temperature=0.7
                    )

                    ai_answer = response.choices[0].message.content

                    # ç»„åˆæœ€ç»ˆå›ç­”
                    final_answer = f"{ai_answer}\n\n---\n\n{search_context}"

                    return final_answer, used_search
                else:
                    # æœç´¢æ— ç»“æœï¼Œä½¿ç”¨æ™®é€šå›ç­”
                    logger.info("Search returned no results, falling back to normal response")

            except Exception as e:
                logger.error(f"Search processing failed: {e}")
                # æœç´¢å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸å¯¹è¯

        # ä¸éœ€è¦æœç´¢æˆ–æœç´¢å¤±è´¥æ—¶çš„æ­£å¸¸å¤„ç†
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": query}],
            max_tokens=1500,
            temperature=0.7
        )

        return response.choices[0].message.content, used_search


# å…¨å±€æœç´¢ç®¡ç†å™¨å®ä¾‹
search_manager = SmartSearchManager()
