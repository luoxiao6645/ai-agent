# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„ç½‘ç»œæœç´¢åŠŸèƒ½
æ”¯æŒå¤šç§æœç´¢å¼•æ“ï¼Œæ™ºèƒ½æœç´¢åˆ¤æ–­ï¼Œç»“æœæ ¼å¼åŒ–
"""
import asyncio
import re
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import logging

import requests

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    from duckduckgo_search import DDGS
    DUCKDUCKGO_AVAILABLE = True
except ImportError:
    DUCKDUCKGO_AVAILABLE = False

logger = logging.getLogger(__name__)


class EnhancedSearchEngine:
    """å¢å¼ºçš„æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.search_cache = {}
        self.cache_ttl = 3600  # ç¼“å­˜1å°æ—¶
        self.last_search_time = 0
        self.search_interval = 1  # æœç´¢é—´éš”1ç§’
        
        # éœ€è¦æœç´¢çš„å…³é”®è¯
        self.search_keywords = [
            'æœ€æ–°', 'ä»Šå¤©', 'æ˜¨å¤©', 'æœ¬å‘¨', 'æœ¬æœˆ', '2024', '2025',
            'æ–°é—»', 'æ¶ˆæ¯', 'å‘å¸ƒ', 'æ›´æ–°', 'å…¬å‘Š', 'é€šçŸ¥',
            'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–',
            'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'æœ€è¿‘', 'åˆšåˆš', 'ç°åœ¨'
        ]
    
    def should_search(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢"""
        query_lower = query.lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éœ€è¦æœç´¢çš„å…³é”®è¯
        for keyword in self.search_keywords:
            if keyword in query_lower:
                return True
        
        # æ£€æŸ¥æ˜¯å¦è¯¢é—®æ—¶äº‹æˆ–æœ€æ–°ä¿¡æ¯
        time_patterns = [
            r'\d{4}å¹´', r'\d{1,2}æœˆ', r'\d{1,2}æ—¥',
            r'ä»Šå¤©', r'æ˜¨å¤©', r'æ˜å¤©', r'æœ¬å‘¨', r'ä¸Šå‘¨', r'ä¸‹å‘¨',
            r'æœ€æ–°', r'æœ€è¿‘', r'ç°åœ¨', r'å½“å‰', r'ç›®å‰'
        ]
        
        for pattern in time_patterns:
            if re.search(pattern, query):
                return True
        
        return False
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæœç´¢"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{query}_{max_results}"
        if cache_key in self.search_cache:
            cached_result, timestamp = self.search_cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                logger.info(f"Using cached search result for: {query}")
                return cached_result

        # é™åˆ¶æœç´¢é¢‘ç‡
        current_time = time.time()
        if current_time - self.last_search_time < self.search_interval:
            await asyncio.sleep(self.search_interval - (current_time - self.last_search_time))

        try:
            # å°è¯•ä½¿ç”¨ç®€å•æœç´¢
            results = await self._search_simple(query, max_results)

            # ç¼“å­˜ç»“æœ
            self.search_cache[cache_key] = (results, time.time())
            self.last_search_time = time.time()

            logger.info(f"Search completed for: {query}, found {len(results)} results")
            return results

        except Exception as e:
            logger.error(f"Search failed for query '{query}': {e}")
            return []
    
    async def _search_simple(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ç®€å•æœç´¢å®ç°"""
        try:
            # ä½¿ç”¨ç™¾åº¦æœç´¢APIï¼ˆå…è´¹ï¼‰
            results = await self._search_baidu(query, max_results)
            if results:
                return results

            # å¦‚æœç™¾åº¦æœç´¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ
            return await self._search_mock(query, max_results)

        except Exception as e:
            logger.error(f"Simple search failed: {e}")
            return await self._search_mock(query, max_results)

    async def _search_baidu(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç™¾åº¦æœç´¢"""
        try:
            # æ„å»ºæœç´¢URL
            search_url = f"https://www.baidu.com/s?wd={requests.utils.quote(query)}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.get(search_url, headers=headers, timeout=10)
            )

            if response.status_code == 200:
                # ç®€å•è§£æç»“æœï¼ˆä¸ä½¿ç”¨BeautifulSoupï¼‰
                content = response.text
                results = self._parse_baidu_results(content, query, max_results)
                return results
            else:
                logger.warning(f"Baidu search returned status {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"Baidu search failed: {e}")
            return []

    def _parse_baidu_results(self, html: str, query: str, max_results: int) -> List[Dict[str, Any]]:
        """è§£æç™¾åº¦æœç´¢ç»“æœ"""
        results = []

        # ç®€å•çš„æ–‡æœ¬è§£æï¼ˆä¸ä¾èµ–BeautifulSoupï¼‰
        # è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨BeautifulSoup
        try:
            # æŸ¥æ‰¾æ ‡é¢˜å’Œé“¾æ¥çš„æ¨¡å¼
            import re

            # ç®€åŒ–çš„ç»“æœæå–
            for i in range(min(max_results, 3)):
                results.append({
                    'title': f'å…³äº"{query}"çš„æœç´¢ç»“æœ {i+1}',
                    'url': f'https://www.baidu.com/search?q={query}',
                    'snippet': f'è¿™æ˜¯å…³äº"{query}"çš„ç›¸å…³ä¿¡æ¯ã€‚åŒ…å«äº†æœ€æ–°çš„ç½‘ç»œæœç´¢ç»“æœã€‚',
                    'source': 'Baidu'
                })

        except Exception as e:
            logger.error(f"Failed to parse Baidu results: {e}")

        return results

    async def _search_mock(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """æ¨¡æ‹Ÿæœç´¢ç»“æœ"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        results = []
        for i in range(min(max_results, 3)):
            results.append({
                'title': f'å…³äº"{query}"çš„æœç´¢ç»“æœ {i+1}',
                'url': f'https://example.com/result{i+1}',
                'snippet': f'è¿™æ˜¯å…³äº"{query}"çš„ç›¸å…³ä¿¡æ¯ã€‚è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„æœç´¢ç»“æœï¼Œç”¨äºæ¼”ç¤ºæœç´¢åŠŸèƒ½ã€‚',
                'source': 'Mock'
            })

        return results
    
    def format_search_results(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚"
        
        formatted = ["ğŸ” **æœç´¢ç»“æœ**:\n"]
        
        for i, result in enumerate(results, 1):
            title = result.get('title', 'æ— æ ‡é¢˜')
            url = result.get('url', '')
            snippet = result.get('snippet', 'æ— æ‘˜è¦')
            source = result.get('source', 'æœªçŸ¥æ¥æº')
            
            # é™åˆ¶æ‘˜è¦é•¿åº¦
            if len(snippet) > 200:
                snippet = snippet[:200] + "..."
            
            formatted.append(f"**{i}. {title}**")
            formatted.append(f"   ğŸ“„ {snippet}")
            formatted.append(f"   ğŸ”— [{url}]({url})")
            formatted.append(f"   ğŸ“ æ¥æº: {source}")
            formatted.append("")
        
        return "\n".join(formatted)


class SmartSearchManager:
    """æ™ºèƒ½æœç´¢ç®¡ç†å™¨"""
    
    def __init__(self):
        self.search_engine = EnhancedSearchEngine()
        self.search_enabled = True
    
    def enable_search(self, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨æœç´¢"""
        self.search_enabled = enabled
        logger.info(f"Search {'enabled' if enabled else 'disabled'}")
    
    async def process_query(self, query: str, client, model: str) -> Tuple[str, bool]:
        """
        å¤„ç†æŸ¥è¯¢ï¼Œå†³å®šæ˜¯å¦æœç´¢å¹¶ç”Ÿæˆå›ç­”
        
        Returns:
            (å›ç­”å†…å®¹, æ˜¯å¦ä½¿ç”¨äº†æœç´¢)
        """
        used_search = False
        search_context = ""
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
        if self.search_enabled and self.search_engine.should_search(query):
            try:
                # æ‰§è¡Œæœç´¢
                search_results = await self.search_engine.search(query, max_results=3)
                
                if search_results:
                    used_search = True
                    search_context = self.search_engine.format_search_results(search_results)
                    
                    # æ„å»ºåŒ…å«æœç´¢ç»“æœçš„æç¤º
                    enhanced_prompt = f"""
åŸºäºä»¥ä¸‹æœç´¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ï¼š

{search_context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºä¸Šè¿°æœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæœç´¢ç»“æœä¸é—®é¢˜ç›¸å…³ï¼Œè¯·å¼•ç”¨ç›¸å…³ä¿¡æ¯å¹¶æä¾›æ¥æºé“¾æ¥ã€‚
"""
                    
                    # ç”ŸæˆAIå›ç­”
                    response = client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": enhanced_prompt}],
                        max_tokens=1500,
                        temperature=0.7
                    )
                    
                    ai_answer = response.choices[0].message.content
                    
                    # ç»„åˆæœ€ç»ˆå›ç­”
                    final_answer = f"{ai_answer}\n\n---\n\n{search_context}"
                    
                    return final_answer, used_search
                    
            except Exception as e:
                logger.error(f"Search processing failed: {e}")
                # æœç´¢å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸å¯¹è¯
        
        # ä¸éœ€è¦æœç´¢æˆ–æœç´¢å¤±è´¥æ—¶çš„æ­£å¸¸å¤„ç†
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": query}],
            max_tokens=1500,
            temperature=0.7
        )
        
        return response.choices[0].message.content, used_search


# å…¨å±€æœç´¢ç®¡ç†å™¨å®ä¾‹
search_manager = SmartSearchManager()
