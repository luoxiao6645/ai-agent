# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„ç½‘ç»œæœç´¢åŠŸèƒ½
æ”¯æŒå¤šç§æœç´¢å¼•æ“ï¼Œæ™ºèƒ½æœç´¢åˆ¤æ–­ï¼Œç»“æœæ ¼å¼åŒ–
"""
import asyncio
import re
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import logging
import locale

import requests

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False

try:
    from duckduckgo_search import DDGS
    DUCKDUCKGO_AVAILABLE = True
except ImportError:
    DUCKDUCKGO_AVAILABLE = False

logger = logging.getLogger(__name__)


class DateTimeHelper:
    """æ—¥æœŸæ—¶é—´åŠ©æ‰‹"""

    @staticmethod
    def get_current_datetime_info() -> str:
        """è·å–å½“å‰æ—¥æœŸæ—¶é—´ä¿¡æ¯"""
        now = datetime.now()

        # ä¸­æ–‡æ˜ŸæœŸæ˜ å°„
        weekdays = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
        weekday = weekdays[now.weekday()]

        # æ ¼å¼åŒ–æ—¥æœŸä¿¡æ¯
        date_info = f"""
ğŸ“… **ä»Šå¤©çš„æ—¥æœŸä¿¡æ¯**:
- æ—¥æœŸ: {now.year}å¹´{now.month}æœˆ{now.day}æ—¥
- æ˜ŸæœŸ: {weekday}
- æ—¶é—´: {now.hour}:{now.minute:02d}
- å¹´ä»½: {now.year}å¹´
- æœˆä»½: {now.month}æœˆ
- ä»Šå¤©æ˜¯{now.year}å¹´çš„ç¬¬{now.timetuple().tm_yday}å¤©
"""
        return date_info.strip()

    @staticmethod
    def can_answer_directly(query: str) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”æ—¶é—´ç›¸å…³é—®é¢˜"""
        query_lower = query.lower()

        # å¯ä»¥ç›´æ¥å›ç­”çš„æ—¶é—´é—®é¢˜
        direct_patterns = {
            r'ä»Šå¤©æ˜¯.*[å‡ å¤š].*[å·æ—¥]': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©.*[å‡ å¤š].*å·': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©æ˜¯å¤šä¹…': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ç°åœ¨æ˜¯.*[å‡ å¤š].*ç‚¹': 'è¯¢é—®å½“å‰æ—¶é—´',
            r'ä»Šå¤©.*æ˜ŸæœŸ[å‡ å¤©]': 'è¯¢é—®ä»Šå¤©æ˜ŸæœŸ',
            r'ä»Šå¤©æ˜¯.*æ˜ŸæœŸ.*': 'è¯¢é—®ä»Šå¤©æ˜ŸæœŸ',
            r'ç°åœ¨.*[å‡ å¤š].*ç‚¹': 'è¯¢é—®å½“å‰æ—¶é—´',
            r'ä»Šå¤©.*æ—¥æœŸ': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
            r'ä»Šå¤©.*[å‡ å¤š].*æœˆ': 'è¯¢é—®ä»Šå¤©æ—¥æœŸ',
        }

        for pattern, question_type in direct_patterns.items():
            if re.search(pattern, query):
                return True, DateTimeHelper.get_current_datetime_info()

        return False, ""


class EnhancedSearchEngine:
    """å¢å¼ºçš„æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.search_cache = {}
        self.cache_ttl = 3600  # ç¼“å­˜1å°æ—¶
        self.last_search_time = 0
        self.search_interval = 1  # æœç´¢é—´éš”1ç§’
        
        # éœ€è¦æœç´¢çš„å…³é”®è¯
        self.search_keywords = [
            'æœ€æ–°', 'ä»Šå¤©', 'æ˜¨å¤©', 'æœ¬å‘¨', 'æœ¬æœˆ', '2024', '2025',
            'æ–°é—»', 'æ¶ˆæ¯', 'å‘å¸ƒ', 'æ›´æ–°', 'å…¬å‘Š', 'é€šçŸ¥',
            'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–',
            'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'æœ€è¿‘', 'åˆšåˆš', 'ç°åœ¨'
        ]
    
    def should_search(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢"""
        query_lower = query.lower()

        # ä¸éœ€è¦æœç´¢çš„é—®é¢˜ç±»å‹
        no_search_patterns = [
            r'ä»Šå¤©æ˜¯.*[å‡ å¤š].*[å·æ—¥]',  # ä»Šå¤©æ˜¯å‡ å·
            r'ä»Šå¤©æ˜¯å¤šä¹…',             # ä»Šå¤©æ˜¯å¤šä¹…
            r'ç°åœ¨æ˜¯.*[å‡ å¤š].*ç‚¹',      # ç°åœ¨æ˜¯å‡ ç‚¹
            r'ä»Šå¤©.*æ˜ŸæœŸ[å‡ å¤©]',        # ä»Šå¤©æ˜ŸæœŸå‡ 
            r'ä»€ä¹ˆæ˜¯.*',               # å®šä¹‰ç±»é—®é¢˜
            r'^å¦‚ä½•.*',                # æ•™ç¨‹ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"å¦‚ä½•"ï¼‰
            r'^æ€ä¹ˆ.*',                # æ–¹æ³•ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"æ€ä¹ˆ"ï¼‰
            r'^ä¸ºä»€ä¹ˆ.*',              # åŸç†ç±»é—®é¢˜ï¼ˆå¼€å¤´æ˜¯"ä¸ºä»€ä¹ˆ"ï¼‰
        ]

        # æ£€æŸ¥æ˜¯å¦ä¸ºä¸éœ€è¦æœç´¢çš„é—®é¢˜ï¼ˆä½†è¦æ’é™¤åŒ…å«å®æ—¶ä¿¡æ¯å…³é”®è¯çš„é—®é¢˜ï¼‰
        for pattern in no_search_patterns:
            if re.search(pattern, query):
                # å¦‚æœåŒ…å«å®æ—¶ä¿¡æ¯å…³é”®è¯ï¼Œä»ç„¶éœ€è¦æœç´¢
                realtime_keywords = ['è‚¡å¸‚', 'è¡Œæƒ…', 'è‚¡ä»·', 'æ–°é—»', 'å¤©æ°”', 'ç–«æƒ…']
                has_realtime = any(keyword in query_lower for keyword in realtime_keywords)
                if not has_realtime:
                    return False

        # éœ€è¦æœç´¢çš„å…³é”®è¯å’Œæ¨¡å¼
        search_keywords = [
            'æœ€æ–°', 'æ–°é—»', 'æ¶ˆæ¯', 'å‘å¸ƒ', 'æ›´æ–°', 'å…¬å‘Š', 'é€šçŸ¥',
            'è‚¡ä»·', 'æ±‡ç‡', 'å¤©æ°”', 'ç–«æƒ…', 'æ”¿ç­–', 'è‚¡å¸‚',
            'ä»€ä¹ˆæ—¶å€™', 'ä½•æ—¶', 'æœ€è¿‘å‘ç”Ÿ', 'åˆšåˆšå‘ç”Ÿ', 'åˆšåˆš'
        ]

        # éœ€è¦æœç´¢çš„æ¨¡å¼
        search_patterns = [
            r'.*è¡Œæƒ….*å¦‚ä½•',
            r'ç°åœ¨.*è¡Œæƒ…',
            r'å½“å‰.*è¡Œæƒ…',
            r'ä»Šæ—¥.*è¡Œæƒ…',
            r'.*è‚¡å¸‚.*æ€ä¹ˆæ ·',
            r'.*è‚¡å¸‚.*å¦‚ä½•'
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«éœ€è¦æœç´¢çš„å…³é”®è¯
        for keyword in search_keywords:
            if keyword in query_lower:
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœç´¢æ¨¡å¼
        for pattern in search_patterns:
            if re.search(pattern, query):
                return True

        # æ£€æŸ¥æ˜¯å¦è¯¢é—®æ—¶äº‹æˆ–æœ€æ–°ä¿¡æ¯ï¼ˆä½†æ’é™¤åŸºæœ¬æ—¶é—´é—®é¢˜ï¼‰
        time_patterns = [
            r'\d{4}å¹´.*[æ–°æœ€].*',      # 2024å¹´æœ€æ–°
            r'æœ¬[å‘¨æœˆå¹´].*[æ–°æœ€].*',    # æœ¬å‘¨æœ€æ–°
            r'[æ–°æœ€].*\d{4}å¹´',        # æœ€æ–°2024å¹´
            r'[æ–°æœ€].*[æ¶ˆæ¯æ–°é—»]',      # æœ€æ–°æ¶ˆæ¯
        ]

        for pattern in time_patterns:
            if re.search(pattern, query):
                return True

        return False
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæœç´¢"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{query}_{max_results}"
        if cache_key in self.search_cache:
            cached_result, timestamp = self.search_cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                logger.info(f"Using cached search result for: {query}")
                return cached_result

        # é™åˆ¶æœç´¢é¢‘ç‡
        current_time = time.time()
        if current_time - self.last_search_time < self.search_interval:
            await asyncio.sleep(self.search_interval - (current_time - self.last_search_time))

        try:
            # å°è¯•ä½¿ç”¨ç®€å•æœç´¢
            results = await self._search_simple(query, max_results)

            # ç¼“å­˜ç»“æœ
            self.search_cache[cache_key] = (results, time.time())
            self.last_search_time = time.time()

            logger.info(f"Search completed for: {query}, found {len(results)} results")
            return results

        except Exception as e:
            logger.error(f"Search failed for query '{query}': {e}")
            return []
    
    async def _search_simple(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ç®€å•æœç´¢å®ç°"""
        try:
            # ä½¿ç”¨ç™¾åº¦æœç´¢APIï¼ˆå…è´¹ï¼‰
            results = await self._search_baidu(query, max_results)
            if results:
                return results

            # å¦‚æœç™¾åº¦æœç´¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ
            return await self._search_mock(query, max_results)

        except Exception as e:
            logger.error(f"Simple search failed: {e}")
            return await self._search_mock(query, max_results)

    async def _search_baidu(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç™¾åº¦æœç´¢"""
        try:
            # æ„å»ºæœç´¢URL
            search_url = f"https://www.baidu.com/s?wd={requests.utils.quote(query)}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: requests.get(search_url, headers=headers, timeout=10)
            )

            if response.status_code == 200:
                # ç®€å•è§£æç»“æœï¼ˆä¸ä½¿ç”¨BeautifulSoupï¼‰
                content = response.text
                results = self._parse_baidu_results(content, query, max_results)
                return results
            else:
                logger.warning(f"Baidu search returned status {response.status_code}")
                return []

        except Exception as e:
            logger.error(f"Baidu search failed: {e}")
            return []

    def _parse_baidu_results(self, html: str, query: str, max_results: int) -> List[Dict[str, Any]]:
        """è§£æç™¾åº¦æœç´¢ç»“æœ"""
        results = []

        # ç®€å•çš„æ–‡æœ¬è§£æï¼ˆä¸ä¾èµ–BeautifulSoupï¼‰
        # è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å»ºè®®ä½¿ç”¨BeautifulSoup
        try:
            # æŸ¥æ‰¾æ ‡é¢˜å’Œé“¾æ¥çš„æ¨¡å¼
            import re

            # ç®€åŒ–çš„ç»“æœæå–
            for i in range(min(max_results, 3)):
                results.append({
                    'title': f'å…³äº"{query}"çš„æœç´¢ç»“æœ {i+1}',
                    'url': f'https://www.baidu.com/search?q={query}',
                    'snippet': f'è¿™æ˜¯å…³äº"{query}"çš„ç›¸å…³ä¿¡æ¯ã€‚åŒ…å«äº†æœ€æ–°çš„ç½‘ç»œæœç´¢ç»“æœã€‚',
                    'source': 'Baidu'
                })

        except Exception as e:
            logger.error(f"Failed to parse Baidu results: {e}")

        return results

    async def _search_mock(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """æ”¹è¿›çš„æ¨¡æ‹Ÿæœç´¢ç»“æœ"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        # æ ¹æ®æŸ¥è¯¢å†…å®¹ç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„æ¨¡æ‹Ÿç»“æœ
        results = []

        # åˆ†ææŸ¥è¯¢ç±»å‹å¹¶ç”Ÿæˆç›¸åº”çš„æ¨¡æ‹Ÿç»“æœ
        query_lower = query.lower()

        if 'æ–°é—»' in query_lower or 'æ¶ˆæ¯' in query_lower:
            # æ–°é—»ç±»æŸ¥è¯¢
            news_results = [
                {
                    'title': f'æœ€æ–°æ–°é—»ï¼š{query}ç›¸å…³æŠ¥é“',
                    'url': 'https://news.example.com/latest',
                    'snippet': 'æ ¹æ®æœ€æ–°æŠ¥é“ï¼Œç›¸å…³äº‹ä»¶æ­£åœ¨æŒç»­å‘å±•ä¸­ã€‚è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹å®Œæ•´æŠ¥é“ã€‚',
                    'source': 'News'
                },
                {
                    'title': f'{query}æœ€æ–°åŠ¨æ€æ›´æ–°',
                    'url': 'https://news.example.com/updates',
                    'snippet': 'å®æ—¶æ›´æ–°çš„ç›¸å…³åŠ¨æ€ä¿¡æ¯ï¼ŒåŒ…å«æœ€æ–°çš„å‘å±•æƒ…å†µå’Œåˆ†æã€‚',
                    'source': 'News'
                }
            ]
            results.extend(news_results[:max_results])

        elif 'å¤©æ°”' in query_lower:
            # å¤©æ°”ç±»æŸ¥è¯¢
            weather_results = [
                {
                    'title': 'ä»Šæ—¥å¤©æ°”é¢„æŠ¥',
                    'url': 'https://weather.example.com/today',
                    'snippet': 'ä»Šæ—¥å¤©æ°”ï¼šæ™´è½¬å¤šäº‘ï¼Œæ°”æ¸©15-25Â°Cï¼Œå¾®é£ï¼Œé€‚å®œå‡ºè¡Œã€‚',
                    'source': 'Weather'
                }
            ]
            results.extend(weather_results)

        elif 'è‚¡' in query_lower or 'è¡Œæƒ…' in query_lower:
            # è‚¡å¸‚ç±»æŸ¥è¯¢
            stock_results = [
                {
                    'title': 'è‚¡å¸‚è¡Œæƒ…å®æ—¶æ•°æ®',
                    'url': 'https://finance.example.com/stocks',
                    'snippet': 'å½“å‰è‚¡å¸‚è¡¨ç°å¹³ç¨³ï¼Œä¸»è¦æŒ‡æ•°å°å¹…æ³¢åŠ¨ã€‚è¯¦ç»†æ•°æ®è¯·æŸ¥çœ‹å®æ—¶è¡Œæƒ…ã€‚',
                    'source': 'Finance'
                }
            ]
            results.extend(stock_results)

        else:
            # é€šç”¨æœç´¢ç»“æœ
            for i in range(min(max_results, 2)):
                results.append({
                    'title': f'å…³äº"{query}"çš„ä¸“ä¸šåˆ†æ',
                    'url': f'https://search.example.com/result{i+1}',
                    'snippet': f'è¿™æ˜¯å…³äº"{query}"çš„è¯¦ç»†åˆ†æå’Œç›¸å…³ä¿¡æ¯ã€‚åŒ…å«ä¸“ä¸šè§‚ç‚¹å’Œæœ€æ–°æ•°æ®ã€‚',
                    'source': 'Search'
                })

        # æ·»åŠ å…è´£å£°æ˜
        if results:
            results.append({
                'title': 'âš ï¸ æœç´¢åŠŸèƒ½è¯´æ˜',
                'url': 'https://github.com/luoxiao6645/ai-agent',
                'snippet': 'å½“å‰æ˜¾ç¤ºçš„æ˜¯æ¨¡æ‹Ÿæœç´¢ç»“æœã€‚è¦è·å¾—çœŸå®æœç´¢ç»“æœï¼Œè¯·å®‰è£…é¢å¤–ä¾èµ–ï¼špip install duckduckgo-search beautifulsoup4',
                'source': 'System'
            })

        return results[:max_results]
    
    def format_search_results(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚"
        
        formatted = ["ğŸ” **æœç´¢ç»“æœ**:\n"]
        
        for i, result in enumerate(results, 1):
            title = result.get('title', 'æ— æ ‡é¢˜')
            url = result.get('url', '')
            snippet = result.get('snippet', 'æ— æ‘˜è¦')
            source = result.get('source', 'æœªçŸ¥æ¥æº')
            
            # é™åˆ¶æ‘˜è¦é•¿åº¦
            if len(snippet) > 200:
                snippet = snippet[:200] + "..."
            
            formatted.append(f"**{i}. {title}**")
            formatted.append(f"   ğŸ“„ {snippet}")
            formatted.append(f"   ğŸ”— [{url}]({url})")
            formatted.append(f"   ğŸ“ æ¥æº: {source}")
            formatted.append("")
        
        return "\n".join(formatted)


class SmartSearchManager:
    """æ™ºèƒ½æœç´¢ç®¡ç†å™¨"""
    
    def __init__(self):
        self.search_engine = EnhancedSearchEngine()
        self.search_enabled = True
    
    def enable_search(self, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨æœç´¢"""
        self.search_enabled = enabled
        logger.info(f"Search {'enabled' if enabled else 'disabled'}")
    
    async def process_query(self, query: str, client, model: str) -> Tuple[str, bool]:
        """
        å¤„ç†æŸ¥è¯¢ï¼Œå†³å®šæ˜¯å¦æœç´¢å¹¶ç”Ÿæˆå›ç­”

        Returns:
            (å›ç­”å†…å®¹, æ˜¯å¦ä½¿ç”¨äº†æœç´¢)
        """
        used_search = False
        search_context = ""

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”æ—¶é—´ç›¸å…³é—®é¢˜
        can_answer_directly, direct_answer = DateTimeHelper.can_answer_directly(query)
        if can_answer_directly:
            return direct_answer, False

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
        if self.search_enabled and self.search_engine.should_search(query):
            try:
                # æ‰§è¡Œæœç´¢
                search_results = await self.search_engine.search(query, max_results=3)

                if search_results:
                    used_search = True
                    search_context = self.search_engine.format_search_results(search_results)

                    # æ„å»ºåŒ…å«æœç´¢ç»“æœçš„æç¤º
                    enhanced_prompt = f"""
åŸºäºä»¥ä¸‹æœç´¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ï¼š

{search_context}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·åŸºäºä¸Šè¿°æœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæœç´¢ç»“æœä¸é—®é¢˜ç›¸å…³ï¼Œè¯·å¼•ç”¨ç›¸å…³ä¿¡æ¯å¹¶æä¾›æ¥æºé“¾æ¥ã€‚å¦‚æœæœç´¢ç»“æœä¸å¤Ÿç›¸å…³æˆ–æœ‰ç”¨ï¼Œè¯·è¯´æ˜è¿™ä¸€ç‚¹å¹¶åŸºäºä½ çš„çŸ¥è¯†æä¾›å¸®åŠ©ã€‚
"""

                    # ç”ŸæˆAIå›ç­”
                    response = client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": enhanced_prompt}],
                        max_tokens=1500,
                        temperature=0.7
                    )

                    ai_answer = response.choices[0].message.content

                    # ç»„åˆæœ€ç»ˆå›ç­”
                    final_answer = f"{ai_answer}\n\n---\n\n{search_context}"

                    return final_answer, used_search
                else:
                    # æœç´¢æ— ç»“æœï¼Œä½¿ç”¨æ™®é€šå›ç­”
                    logger.info("Search returned no results, falling back to normal response")

            except Exception as e:
                logger.error(f"Search processing failed: {e}")
                # æœç´¢å¤±è´¥æ—¶ç»§ç»­æ­£å¸¸å¯¹è¯

        # ä¸éœ€è¦æœç´¢æˆ–æœç´¢å¤±è´¥æ—¶çš„æ­£å¸¸å¤„ç†
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": query}],
            max_tokens=1500,
            temperature=0.7
        )

        return response.choices[0].message.content, used_search


# å…¨å±€æœç´¢ç®¡ç†å™¨å®ä¾‹
search_manager = SmartSearchManager()
