"""
é›†æˆç‰ˆæ™ºèƒ½å¤šæ¨¡æ€AI Agent - Streamlitåº”ç”¨
ç»“åˆç®€åŒ–ç‰ˆçš„ç¨³å®šæ€§å’Œå®Œæ•´ç‰ˆçš„åŠŸèƒ½
"""
import streamlit as st
import os
import sys
import asyncio
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®å·²åœ¨app.pyä¸­è®¾ç½®ï¼Œè¿™é‡Œä¸å†é‡å¤è®¾ç½®

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
@st.cache_resource
def init_client():
    """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
    try:
        client = OpenAI(
            base_url=os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3"),
            api_key=os.getenv("ARK_API_KEY"),
        )
        return client
    except Exception as e:
        st.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

# å°è¯•å¯¼å…¥å®Œæ•´ç³»ç»Ÿç»„ä»¶
def try_import_full_system():
    """å°è¯•å¯¼å…¥å®Œæ•´ç³»ç»Ÿç»„ä»¶"""
    try:
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))

        from multimodal_agent.core.agent import MultiModalAgent
        from multimodal_agent.tools.tool_manager import ToolManager
        from config import Config
        return True, MultiModalAgent, ToolManager, Config
    except Exception as e:
        # ä¸æ˜¾ç¤ºè­¦å‘Šï¼Œé™é»˜å¤„ç†
        return False, None, None, None

# æ£€æŸ¥ç³»ç»Ÿèƒ½åŠ›
FULL_SYSTEM_AVAILABLE, MultiModalAgent, ToolManager, Config = try_import_full_system()

def main():
    """ä¸»ç•Œé¢"""
    st.title("ğŸ¤– æ™ºèƒ½å¤šæ¨¡æ€AI Agentç³»ç»Ÿ")
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    if FULL_SYSTEM_AVAILABLE:
        st.success("âœ… å®Œæ•´å¤šæ¨¡æ€ç³»ç»Ÿå·²å¯ç”¨")
        system_mode = "å®Œæ•´ç‰ˆ"
    else:
        st.info("â„¹ï¸ ä½¿ç”¨ç®€åŒ–ç‰ˆç³»ç»Ÿ")
        system_mode = "ç®€åŒ–ç‰ˆ"
    
    st.markdown(f"**å½“å‰æ¨¡å¼**: {system_mode}")
    st.markdown("---")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = init_client()
    if not client:
        st.error("âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
        return
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ› ï¸ ç³»ç»Ÿæ§åˆ¶")
        
        # ç³»ç»ŸçŠ¶æ€
        st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        st.success("âœ… AIå®¢æˆ·ç«¯å·²è¿æ¥")
        st.info(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')}")
        st.info(f"ğŸ”§ æ¨¡å¼: {system_mode}")
        
        # æ¨¡å‹é…ç½®
        st.subheader("âš™ï¸ æ¨¡å‹é…ç½®")
        model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            [os.getenv("ARK_MODEL", "ep-20250506230532-w7rdw")],
            index=0
        )
        
        temperature = st.slider("æ¸©åº¦", 0.0, 1.0, 0.7, 0.1)
        max_tokens = st.slider("æœ€å¤§ä»¤ç‰Œæ•°", 100, 2000, 500, 100)
        
        # æ¸…é™¤å¯¹è¯
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯"):
            st.session_state.messages = []
            st.session_state.conversation_history = []
            st.rerun()
        
        # æ˜¾ç¤ºå¯ç”¨å·¥å…·ï¼ˆå¦‚æœæ˜¯å®Œæ•´ç‰ˆï¼‰
        if FULL_SYSTEM_AVAILABLE:
            st.subheader("ğŸ”§ å¯ç”¨å·¥å…·")
            try:
                if 'agent' in st.session_state:
                    tools = st.session_state.agent.tool_manager.get_tool_names()
                    for tool in tools[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        st.text(f"â€¢ {tool}")
                    if len(tools) > 5:
                        st.text(f"... è¿˜æœ‰ {len(tools)-5} ä¸ªå·¥å…·")
            except:
                st.text("å·¥å…·ä¿¡æ¯åŠ è½½ä¸­...")
    
    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    if FULL_SYSTEM_AVAILABLE:
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“ æ–‡ä»¶å¤„ç†", "ğŸ§® å·¥å…·ç®±", "ğŸ§  è®°å¿†ç®¡ç†"])
        
        with tab1:
            enhanced_chat_interface(client, model, temperature, max_tokens)
        
        with tab2:
            enhanced_file_interface(client, model)
        
        with tab3:
            enhanced_tools_interface(client, model)
        
        with tab4:
            memory_interface()
    else:
        tab1, tab2, tab3 = st.tabs(["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“ æ–‡ä»¶å¤„ç†", "ğŸ§® å·¥å…·ç®±"])
        
        with tab1:
            simple_chat_interface(client, model, temperature, max_tokens)
        
        with tab2:
            simple_file_interface(client, model)
        
        with tab3:
            simple_tools_interface(client, model)

def enhanced_chat_interface(client, model, temperature, max_tokens):
    """å¢å¼ºç‰ˆå¯¹è¯ç•Œé¢ï¼ˆå®Œæ•´ç³»ç»Ÿï¼‰"""
    st.header("ğŸ’¬ æ™ºèƒ½å¯¹è¯")
    
    # åˆå§‹åŒ–å®Œæ•´Agent
    if 'agent' not in st.session_state and FULL_SYSTEM_AVAILABLE:
        try:
            with st.spinner("åˆå§‹åŒ–å®Œæ•´AI Agentç³»ç»Ÿ..."):
                st.session_state.agent = MultiModalAgent()
                st.success("âœ… å®Œæ•´AI Agentç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            st.error(f"å®Œæ•´ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            st.info("å›é€€åˆ°ç®€åŒ–ç‰ˆå¯¹è¯ç•Œé¢")
            simple_chat_interface(client, model, temperature, max_tokens)
            return
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "processing_time" in message:
                st.caption(f"å¤„ç†æ—¶é—´: {message['processing_time']:.2f}ç§’")
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”ŸæˆAIå›å¤ï¼ˆä½¿ç”¨å®Œæ•´Agentï¼‰
        with st.chat_message("assistant"):
            with st.spinner("AI Agentæ­£åœ¨æ€è€ƒ..."):
                try:
                    # ä½¿ç”¨å®Œæ•´çš„å¤šæ¨¡æ€Agentå¤„ç†
                    input_data = {
                        "type": "text",
                        "content": prompt
                    }
                    
                    result = asyncio.run(st.session_state.agent.process_input(input_data))
                    assistant_response = result.get('response', 'å¤„ç†å¤±è´¥')
                    processing_time = result.get('processing_time', 0)
                    
                    st.markdown(assistant_response)
                    
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": assistant_response,
                        "processing_time": processing_time
                    })
                    
                except Exception as e:
                    error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": error_msg
                    })

def simple_chat_interface(client, model, temperature, max_tokens):
    """ç®€åŒ–ç‰ˆå¯¹è¯ç•Œé¢"""
    st.header("ğŸ’¬ æ™ºèƒ½å¯¹è¯")
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
                try:
                    # æ„å»ºæ¶ˆæ¯å†å²
                    messages = [
                        {"role": "system", "content": "ä½ æ˜¯è±†åŒ…AIåŠ©æ‰‹ï¼Œä¸€ä¸ªæ™ºèƒ½ã€å‹å¥½ã€æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"}
                    ]
                    messages.extend(st.session_state.messages)
                    
                    # è°ƒç”¨API
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        temperature=temperature,
                        max_tokens=max_tokens
                    )
                    
                    assistant_response = response.choices[0].message.content
                    st.markdown(assistant_response)
                    
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": assistant_response
                    })
                    
                except Exception as e:
                    st.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")

def enhanced_file_interface(client, model):
    """å¢å¼ºç‰ˆæ–‡ä»¶å¤„ç†ç•Œé¢"""
    st.header("ğŸ“ æ–‡ä»¶å¤„ç†")
    st.info("ğŸš€ ä½¿ç”¨å®Œæ•´å¤šæ¨¡æ€å¤„ç†ç³»ç»Ÿ")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶", 
        type=['txt', 'md', 'json', 'csv', 'pdf', 'docx', 'xlsx'],
        help="æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼çš„æ™ºèƒ½è§£æ"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {uploaded_file.name}")
        st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size} å­—èŠ‚")
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“– æ™ºèƒ½è§£æ"):
                process_file_with_agent(temp_path, "è§£æ")
        
        with col2:
            if st.button("ğŸ“Š å†…å®¹æ‘˜è¦"):
                process_file_with_agent(temp_path, "æ‘˜è¦")
        
        with col3:
            if st.button("ğŸ” å…³é”®ä¿¡æ¯æå–"):
                process_file_with_agent(temp_path, "æå–")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(temp_path)
        except:
            pass

def simple_file_interface(client, model):
    """ç®€åŒ–ç‰ˆæ–‡ä»¶å¤„ç†ç•Œé¢"""
    st.header("ğŸ“ æ–‡ä»¶å¤„ç†")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶", 
        type=['txt', 'md', 'json', 'csv'],
        help="æ”¯æŒæ–‡æœ¬æ–‡ä»¶ã€Markdownã€JSONã€CSVæ ¼å¼"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {uploaded_file.name}")
        st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size} å­—èŠ‚")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            if uploaded_file.type == "text/plain" or uploaded_file.name.endswith('.md'):
                content = uploaded_file.read().decode('utf-8')
            elif uploaded_file.name.endswith('.json'):
                content = json.dumps(json.load(uploaded_file), ensure_ascii=False, indent=2)
            elif uploaded_file.name.endswith('.csv'):
                content = uploaded_file.read().decode('utf-8')
            else:
                content = str(uploaded_file.read())
            
            # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹é¢„è§ˆ
            st.subheader("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ")
            st.text_area("å†…å®¹", value=content[:1000] + "..." if len(content) > 1000 else content, height=200)
            
            # æ–‡ä»¶åˆ†æé€‰é¡¹
            st.subheader("ğŸ” æ–‡ä»¶åˆ†æ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ“Š å†…å®¹æ‘˜è¦"):
                    analyze_file_content(client, model, content, "è¯·å¯¹ä»¥ä¸‹æ–‡ä»¶å†…å®¹è¿›è¡Œæ‘˜è¦æ€»ç»“")
            
            with col2:
                if st.button("ğŸ” å…³é”®ä¿¡æ¯æå–"):
                    analyze_file_content(client, model, content, "è¯·æå–ä»¥ä¸‹æ–‡ä»¶å†…å®¹ä¸­çš„å…³é”®ä¿¡æ¯")
            
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

def process_file_with_agent(file_path, action):
    """ä½¿ç”¨Agentå¤„ç†æ–‡ä»¶"""
    if 'agent' not in st.session_state:
        st.error("Agentæœªåˆå§‹åŒ–")
        return
    
    with st.spinner(f"æ­£åœ¨{action}æ–‡ä»¶..."):
        try:
            input_data = {
                "type": "file",
                "content": file_path
            }
            
            result = asyncio.run(st.session_state.agent.process_input(input_data))
            
            st.success(f"âœ… {action}å®Œæˆ")
            st.markdown("### å¤„ç†ç»“æœ")
            st.markdown(result.get('response', 'å¤„ç†å¤±è´¥'))
            
            if 'processing_time' in result:
                st.caption(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
                
        except Exception as e:
            st.error(f"{action}å¤±è´¥: {str(e)}")

def analyze_file_content(client, model, content, instruction):
    """åˆ†ææ–‡ä»¶å†…å®¹"""
    with st.spinner("AIæ­£åœ¨åˆ†ææ–‡ä»¶..."):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": f"{instruction}:\n\n{content[:3000]}"}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            result = response.choices[0].message.content
            st.success("âœ… åˆ†æå®Œæˆ")
            st.markdown("### åˆ†æç»“æœ")
            st.markdown(result)
            
        except Exception as e:
            st.error(f"åˆ†æå¤±è´¥: {e}")

def enhanced_tools_interface(client, model):
    """å¢å¼ºç‰ˆå·¥å…·ç®±ç•Œé¢"""
    st.header("ğŸ§® AIå·¥å…·ç®±")
    st.info("ğŸš€ ä½¿ç”¨å®Œæ•´å·¥å…·é“¾ç³»ç»Ÿ")

    if 'agent' not in st.session_state:
        st.error("Agentæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨å·¥å…·")
        return

    # å·¥å…·ç±»åˆ«é€‰æ‹©
    tool_category = st.selectbox(
        "é€‰æ‹©å·¥å…·ç±»åˆ«",
        ["ğŸ’­ åˆ›æ„å†™ä½œ", "ğŸ”¤ æ–‡æœ¬ç¿»è¯‘", "ğŸ“ å†…å®¹æ”¹å†™", "ğŸ§® æ•°å­¦è®¡ç®—", "ğŸ“Š æ•°æ®åˆ†æ", "ğŸ” ç½‘ç»œæœç´¢", "ğŸ’» ä»£ç æ‰§è¡Œ"]
    )

    if tool_category == "ğŸ’­ åˆ›æ„å†™ä½œ":
        creative_writing_tool_enhanced(client, model)
    elif tool_category == "ğŸ”¤ æ–‡æœ¬ç¿»è¯‘":
        translation_tool_enhanced(client, model)
    elif tool_category == "ğŸ“ å†…å®¹æ”¹å†™":
        rewriting_tool_enhanced(client, model)
    elif tool_category == "ğŸ§® æ•°å­¦è®¡ç®—":
        math_tool_enhanced(client, model)
    elif tool_category == "ğŸ“Š æ•°æ®åˆ†æ":
        data_analysis_tool_enhanced(client, model)
    elif tool_category == "ğŸ” ç½‘ç»œæœç´¢":
        web_search_tool_enhanced()
    elif tool_category == "ğŸ’» ä»£ç æ‰§è¡Œ":
        code_execution_tool_enhanced()

def simple_tools_interface(client, model):
    """ç®€åŒ–ç‰ˆå·¥å…·ç®±ç•Œé¢"""
    st.header("ğŸ§® AIå·¥å…·ç®±")

    # å·¥å…·é€‰æ‹©
    tool_option = st.selectbox(
        "é€‰æ‹©å·¥å…·",
        ["ğŸ’­ åˆ›æ„å†™ä½œ", "ğŸ”¤ æ–‡æœ¬ç¿»è¯‘", "ğŸ“ å†…å®¹æ”¹å†™", "ğŸ§® æ•°å­¦è®¡ç®—", "ğŸ“Š æ•°æ®åˆ†æ"]
    )

    if tool_option == "ğŸ’­ åˆ›æ„å†™ä½œ":
        creative_writing_tool(client, model)
    elif tool_option == "ğŸ”¤ æ–‡æœ¬ç¿»è¯‘":
        translation_tool(client, model)
    elif tool_option == "ğŸ“ å†…å®¹æ”¹å†™":
        rewriting_tool(client, model)
    elif tool_option == "ğŸ§® æ•°å­¦è®¡ç®—":
        math_tool(client, model)
    elif tool_option == "ğŸ“Š æ•°æ®åˆ†æ":
        data_analysis_tool(client, model)

def memory_interface():
    """è®°å¿†ç®¡ç†ç•Œé¢"""
    st.header("ğŸ§  è®°å¿†ç®¡ç†")

    if 'agent' not in st.session_state:
        st.error("Agentæœªåˆå§‹åŒ–ï¼Œæ— æ³•è®¿é—®è®°å¿†ç³»ç»Ÿ")
        return

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ” æœç´¢è®°å¿†")
        search_query = st.text_input("è¾“å…¥æœç´¢å…³é”®è¯")
        if st.button("æœç´¢") and search_query:
            search_memory_enhanced(search_query)

    with col2:
        st.subheader("ğŸ“Š è®°å¿†ç»Ÿè®¡")
        if st.button("æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯"):
            show_memory_stats()

    st.subheader("ğŸ—‘ï¸ è®°å¿†ç®¡ç†")
    col3, col4 = st.columns(2)

    with col3:
        if st.button("æ¸…é™¤æ‰€æœ‰è®°å¿†", type="secondary"):
            clear_all_memory()

    with col4:
        if st.button("å¯¼å‡ºè®°å¿†", type="secondary"):
            export_memory()

def search_memory_enhanced(query):
    """å¢å¼ºç‰ˆè®°å¿†æœç´¢"""
    with st.spinner("æœç´¢è®°å¿†ä¸­..."):
        try:
            results = asyncio.run(st.session_state.agent.search_memory(query))

            if results:
                st.success(f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†")
                for i, result in enumerate(results):
                    with st.expander(f"è®°å¿† {i+1}"):
                        st.text(result.page_content)
                        if hasattr(result, 'metadata') and result.metadata:
                            st.json(result.metadata)
            else:
                st.info("æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")

        except Exception as e:
            st.error(f"æœç´¢å¤±è´¥: {str(e)}")

def show_memory_stats():
    """æ˜¾ç¤ºè®°å¿†ç»Ÿè®¡"""
    try:
        stats = st.session_state.agent.memory_manager.get_memory_stats()
        st.json(stats)
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

def clear_all_memory():
    """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
    if st.button("ç¡®è®¤æ¸…é™¤", type="primary"):
        try:
            asyncio.run(st.session_state.agent.clear_memory())
            st.success("âœ… æ‰€æœ‰è®°å¿†å·²æ¸…é™¤")
        except Exception as e:
            st.error(f"æ¸…é™¤å¤±è´¥: {str(e)}")

def export_memory():
    """å¯¼å‡ºè®°å¿†"""
    st.info("è®°å¿†å¯¼å‡ºåŠŸèƒ½å¼€å‘ä¸­...")

# å¢å¼ºç‰ˆå·¥å…·å‡½æ•°
def creative_writing_tool_enhanced(client, model):
    """å¢å¼ºç‰ˆåˆ›æ„å†™ä½œå·¥å…·"""
    st.subheader("ğŸ’­ åˆ›æ„å†™ä½œåŠ©æ‰‹")

    writing_type = st.selectbox("å†™ä½œç±»å‹", ["æ–‡ç« ", "æ•…äº‹", "è¯—æ­Œ", "å¹¿å‘Šæ–‡æ¡ˆ", "é‚®ä»¶", "æŠ¥å‘Š", "æ¼”è®²ç¨¿"])
    topic = st.text_input("ä¸»é¢˜æˆ–å…³é”®è¯")
    style = st.selectbox("å†™ä½œé£æ ¼", ["æ­£å¼", "è½»æ¾", "å¹½é»˜", "ä¸“ä¸š", "åˆ›æ„", "å­¦æœ¯", "å•†åŠ¡"])
    length = st.selectbox("é•¿åº¦", ["ç®€çŸ­", "ä¸­ç­‰", "è¯¦ç»†", "é•¿ç¯‡"])

    if st.button("âœ¨ å¼€å§‹åˆ›ä½œ") and topic:
        use_agent_tool("åˆ›æ„å†™ä½œ", {
            "type": writing_type,
            "topic": topic,
            "style": style,
            "length": length
        })

def translation_tool_enhanced(client, model):
    """å¢å¼ºç‰ˆç¿»è¯‘å·¥å…·"""
    st.subheader("ğŸ”¤ æ™ºèƒ½ç¿»è¯‘")

    source_lang = st.selectbox("æºè¯­è¨€", ["è‡ªåŠ¨æ£€æµ‹", "ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "éŸ©æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "ä¿„æ–‡"])
    target_lang = st.selectbox("ç›®æ ‡è¯­è¨€", ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "éŸ©æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "ä¿„æ–‡"])

    text_to_translate = st.text_area("è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬", height=150)

    if st.button("ğŸ”„ ç¿»è¯‘") and text_to_translate:
        use_agent_tool("ç¿»è¯‘", {
            "source_lang": source_lang,
            "target_lang": target_lang,
            "text": text_to_translate
        })

def use_agent_tool(tool_name, parameters):
    """ä½¿ç”¨Agentå·¥å…·"""
    with st.spinner(f"æ­£åœ¨ä½¿ç”¨{tool_name}å·¥å…·..."):
        try:
            # æ„å»ºæç¤º
            prompt = f"è¯·ä½¿ç”¨{tool_name}å·¥å…·å¤„ç†ä»¥ä¸‹è¯·æ±‚ï¼š{parameters}"

            input_data = {
                "type": "text",
                "content": prompt
            }

            result = asyncio.run(st.session_state.agent.process_input(input_data))

            st.success(f"âœ… {tool_name}å®Œæˆ")
            st.markdown("### å¤„ç†ç»“æœ")
            st.markdown(result.get('response', 'å¤„ç†å¤±è´¥'))

            if 'processing_time' in result:
                st.caption(f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")

        except Exception as e:
            st.error(f"{tool_name}å¤±è´¥: {str(e)}")

# ç®€åŒ–ç‰ˆå·¥å…·å‡½æ•°ï¼ˆä¿æŒåŸæœ‰å®ç°ï¼‰
def creative_writing_tool(client, model):
    """åˆ›æ„å†™ä½œå·¥å…·"""
    st.subheader("ğŸ’­ åˆ›æ„å†™ä½œåŠ©æ‰‹")

    writing_type = st.selectbox("å†™ä½œç±»å‹", ["æ–‡ç« ", "æ•…äº‹", "è¯—æ­Œ", "å¹¿å‘Šæ–‡æ¡ˆ", "é‚®ä»¶"])
    topic = st.text_input("ä¸»é¢˜æˆ–å…³é”®è¯")
    style = st.selectbox("å†™ä½œé£æ ¼", ["æ­£å¼", "è½»æ¾", "å¹½é»˜", "ä¸“ä¸š", "åˆ›æ„"])
    length = st.selectbox("é•¿åº¦", ["ç®€çŸ­", "ä¸­ç­‰", "è¯¦ç»†"])

    if st.button("âœ¨ å¼€å§‹åˆ›ä½œ") and topic:
        with st.spinner("AIæ­£åœ¨åˆ›ä½œ..."):
            try:
                prompt = f"è¯·å†™ä¸€ç¯‡{style}é£æ ¼çš„{writing_type}ï¼Œä¸»é¢˜æ˜¯ï¼š{topic}ã€‚é•¿åº¦è¦æ±‚ï¼š{length}ã€‚"

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ›æ„å†™ä½œåŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.8,
                    max_tokens=1000
                )

                result = response.choices[0].message.content
                st.success("âœ… åˆ›ä½œå®Œæˆ")
                st.markdown("### åˆ›ä½œç»“æœ")
                st.markdown(result)

            except Exception as e:
                st.error(f"åˆ›ä½œå¤±è´¥: {e}")

def translation_tool(client, model):
    """ç¿»è¯‘å·¥å…·"""
    st.subheader("ğŸ”¤ æ™ºèƒ½ç¿»è¯‘")

    source_lang = st.selectbox("æºè¯­è¨€", ["è‡ªåŠ¨æ£€æµ‹", "ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "éŸ©æ–‡", "æ³•æ–‡", "å¾·æ–‡"])
    target_lang = st.selectbox("ç›®æ ‡è¯­è¨€", ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "éŸ©æ–‡", "æ³•æ–‡", "å¾·æ–‡"])

    text_to_translate = st.text_area("è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬", height=150)

    if st.button("ğŸ”„ ç¿»è¯‘") and text_to_translate:
        with st.spinner("AIæ­£åœ¨ç¿»è¯‘..."):
            try:
                prompt = f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬ä»{source_lang}ç¿»è¯‘ä¸º{target_lang}ï¼š\n\n{text_to_translate}"

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œæä¾›å‡†ç¡®ã€è‡ªç„¶çš„ç¿»è¯‘ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=800
                )

                result = response.choices[0].message.content
                st.success("âœ… ç¿»è¯‘å®Œæˆ")
                st.markdown("### ç¿»è¯‘ç»“æœ")
                st.markdown(result)

            except Exception as e:
                st.error(f"ç¿»è¯‘å¤±è´¥: {e}")

def rewriting_tool(client, model):
    """å†…å®¹æ”¹å†™å·¥å…·"""
    st.subheader("ğŸ“ å†…å®¹æ”¹å†™")

    rewrite_style = st.selectbox("æ”¹å†™é£æ ¼", ["æ›´æ­£å¼", "æ›´ç®€æ´", "æ›´è¯¦ç»†", "æ›´é€šä¿—", "æ›´ä¸“ä¸š"])
    original_text = st.text_area("è¯·è¾“å…¥åŸå§‹æ–‡æœ¬", height=150)

    if st.button("âœï¸ æ”¹å†™") and original_text:
        with st.spinner("AIæ­£åœ¨æ”¹å†™..."):
            try:
                prompt = f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ”¹å†™å¾—{rewrite_style}ï¼š\n\n{original_text}"

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘åŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=800
                )

                result = response.choices[0].message.content
                st.success("âœ… æ”¹å†™å®Œæˆ")
                st.markdown("### æ”¹å†™ç»“æœ")
                st.markdown(result)

            except Exception as e:
                st.error(f"æ”¹å†™å¤±è´¥: {e}")

def math_tool(client, model):
    """æ•°å­¦è®¡ç®—å·¥å…·"""
    st.subheader("ğŸ§® æ•°å­¦è®¡ç®—åŠ©æ‰‹")

    math_problem = st.text_area("è¯·è¾“å…¥æ•°å­¦é—®é¢˜æˆ–è®¡ç®—è¡¨è¾¾å¼", height=100)

    if st.button("ğŸ”¢ è®¡ç®—") and math_problem:
        with st.spinner("AIæ­£åœ¨è®¡ç®—..."):
            try:
                prompt = f"è¯·è§£å†³ä»¥ä¸‹æ•°å­¦é—®é¢˜ï¼Œæä¾›è¯¦ç»†çš„è§£é¢˜æ­¥éª¤ï¼š\n\n{math_problem}"

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦åŠ©æ‰‹ï¼Œæ“…é•¿è§£å†³å„ç§æ•°å­¦é—®é¢˜ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=800
                )

                result = response.choices[0].message.content
                st.success("âœ… è®¡ç®—å®Œæˆ")
                st.markdown("### è®¡ç®—ç»“æœ")
                st.markdown(result)

            except Exception as e:
                st.error(f"è®¡ç®—å¤±è´¥: {e}")

def data_analysis_tool(client, model):
    """æ•°æ®åˆ†æå·¥å…·"""
    st.subheader("ğŸ“Š æ•°æ®åˆ†æåŠ©æ‰‹")

    data_input = st.text_area("è¯·è¾“å…¥æ•°æ®ï¼ˆæ”¯æŒCSVæ ¼å¼æˆ–æè¿°æ•°æ®ï¼‰", height=150)
    analysis_type = st.selectbox("åˆ†æç±»å‹", ["åŸºç¡€ç»Ÿè®¡", "è¶‹åŠ¿åˆ†æ", "æ•°æ®æ€»ç»“", "å¼‚å¸¸æ£€æµ‹"])

    if st.button("ğŸ“ˆ åˆ†æ") and data_input:
        with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®..."):
            try:
                prompt = f"è¯·å¯¹ä»¥ä¸‹æ•°æ®è¿›è¡Œ{analysis_type}ï¼š\n\n{data_input}"

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿æ•°æ®åˆ†æå’Œè§£é‡Šã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=800
                )

                result = response.choices[0].message.content
                st.success("âœ… åˆ†æå®Œæˆ")
                st.markdown("### åˆ†æç»“æœ")
                st.markdown(result)

            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {e}")

# å¢å¼ºç‰ˆå·¥å…·çš„å…¶ä»–å®ç°
def rewriting_tool_enhanced(client, model):
    """å¢å¼ºç‰ˆå†…å®¹æ”¹å†™å·¥å…·"""
    rewriting_tool(client, model)  # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆå®ç°

def math_tool_enhanced(client, model):
    """å¢å¼ºç‰ˆæ•°å­¦è®¡ç®—å·¥å…·"""
    math_tool(client, model)  # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆå®ç°

def data_analysis_tool_enhanced(client, model):
    """å¢å¼ºç‰ˆæ•°æ®åˆ†æå·¥å…·"""
    data_analysis_tool(client, model)  # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆå®ç°

def web_search_tool_enhanced():
    """ç½‘ç»œæœç´¢å·¥å…·"""
    st.subheader("ğŸ” ç½‘ç»œæœç´¢")
    st.info("ç½‘ç»œæœç´¢åŠŸèƒ½å¼€å‘ä¸­...")

def code_execution_tool_enhanced():
    """ä»£ç æ‰§è¡Œå·¥å…·"""
    st.subheader("ğŸ’» ä»£ç æ‰§è¡Œ")
    st.info("ä»£ç æ‰§è¡ŒåŠŸèƒ½å¼€å‘ä¸­...")

# ä¸»å‡½æ•°å¯ä»¥è¢«app.pyå¯¼å…¥å’Œè°ƒç”¨
if __name__ == "__main__":
    main()
