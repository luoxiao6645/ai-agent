# -*- coding: utf-8 -*-
"""
å…¬å…±å·¥å…·æ¨¡å— - ä¸ºStreamlitåº”ç”¨æä¾›é€šç”¨åŠŸèƒ½
"""
import os
import streamlit as st
from datetime import datetime
from typing import Optional, Tuple, Any
from openai import OpenAI


class APIClientManager:
    """APIå®¢æˆ·ç«¯ç®¡ç†å™¨"""
    
    @staticmethod
    def create_openai_client() -> Optional[Tuple[OpenAI, str]]:
        """åˆ›å»ºOpenAIå®¢æˆ·ç«¯"""
        try:
            # æ£€æŸ¥ç«å±±æ–¹èˆŸAPIå¯†é’¥
            ark_api_key = None
            if hasattr(st, 'secrets'):
                ark_api_key = st.secrets.get("ARK_API_KEY", None)
            if not ark_api_key:
                ark_api_key = os.getenv("ARK_API_KEY")
            
            if ark_api_key and ark_api_key not in ["your_volcano_engine_ark_api_key_here", ""]:
                # ä½¿ç”¨ç«å±±æ–¹èˆŸAPI
                base_url = os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
                model = os.getenv("ARK_MODEL", "ep-20250506230532-w7rdw")
                
                if hasattr(st, 'secrets'):
                    base_url = st.secrets.get("ARK_BASE_URL", base_url)
                    model = st.secrets.get("ARK_MODEL", model)
                
                client = OpenAI(
                    api_key=ark_api_key,
                    base_url=base_url
                )
                return client, model
            
            # æ£€æŸ¥OpenAI APIå¯†é’¥
            openai_api_key = None
            if hasattr(st, 'secrets'):
                openai_api_key = st.secrets.get("OPENAI_API_KEY", None)
            if not openai_api_key:
                openai_api_key = os.getenv("OPENAI_API_KEY")
            
            if openai_api_key and openai_api_key not in ["your_openai_api_key_here", ""]:
                # ä½¿ç”¨OpenAI API
                client = OpenAI(api_key=openai_api_key)
                model = "gpt-3.5-turbo"
                return client, model
            
            return None
            
        except Exception as e:
            st.error(f"åˆ›å»ºAPIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def test_api_connection(client: OpenAI, model: str) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10,
                timeout=10
            )
            return True
        except Exception:
            return False


class StreamlitUIHelper:
    """Streamlit UIåŠ©æ‰‹"""
    
    @staticmethod
    def setup_page_config():
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="æ™ºèƒ½AIåŠ©æ‰‹",
            page_icon="ğŸ¤–",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    @staticmethod
    def show_api_config_guide():
        """æ˜¾ç¤ºAPIé…ç½®æŒ‡å—"""
        st.markdown("""
        ### ğŸ”‘ APIå¯†é’¥é…ç½®æŒ‡å—
        
        è¯·é…ç½®ä»¥ä¸‹ä»»ä¸€APIå¯†é’¥ï¼š
        
        #### æ–¹æ³•1: ç«å±±æ–¹èˆŸAPI (æ¨è)
        1. è®¿é—® [ç«å±±æ–¹èˆŸæ§åˆ¶å°](https://console.volcengine.com/ark)
        2. åˆ›å»ºAPIå¯†é’¥
        3. åœ¨Streamlit Cloudçš„Secretsä¸­æ·»åŠ ï¼š
        ```toml
        ARK_API_KEY = "your_ark_api_key_here"
        ARK_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
        ARK_MODEL = "your_model_endpoint"
        ```
        
        #### æ–¹æ³•2: OpenAI API
        1. è®¿é—® [OpenAIå¹³å°](https://platform.openai.com/api-keys)
        2. åˆ›å»ºAPIå¯†é’¥
        3. åœ¨Streamlit Cloudçš„Secretsä¸­æ·»åŠ ï¼š
        ```toml
        OPENAI_API_KEY = "your_openai_api_key_here"
        ```
        """)
    
    @staticmethod
    def show_sidebar_info():
        """æ˜¾ç¤ºä¾§è¾¹æ ä¿¡æ¯"""
        with st.sidebar:
            st.markdown("### ğŸ¤– æ™ºèƒ½AIåŠ©æ‰‹")
            st.markdown("---")
            
            st.markdown("#### âœ¨ åŠŸèƒ½ç‰¹æ€§")
            st.markdown("""
            - ğŸ’¬ æ™ºèƒ½å¯¹è¯äº¤æµ
            - ğŸ“ æ–‡ä»¶å†…å®¹åˆ†æ
            - ğŸ” æ–‡æœ¬æ€»ç»“åˆ†æ
            - ğŸ¯ å¤šç§å¤„ç†æ¨¡å¼
            """)
            
            st.markdown("#### ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
            if 'chat_count' not in st.session_state:
                st.session_state.chat_count = 0
            st.metric("å¯¹è¯æ¬¡æ•°", st.session_state.chat_count)
            
            st.markdown("---")
            st.markdown("#### ğŸ’¡ ä½¿ç”¨æç¤º")
            st.markdown("""
            - ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯
            - ä¸Šä¼ æ–‡ä»¶è¿›è¡ŒAIåˆ†æ
            - æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
            """)


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""
    
    @staticmethod
    def show_file_info(uploaded_file):
        """æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯"""
        st.markdown("#### ğŸ“‹ æ–‡ä»¶ä¿¡æ¯")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ–‡ä»¶å", uploaded_file.name)
        with col2:
            st.metric("æ–‡ä»¶å¤§å°", f"{uploaded_file.size / 1024:.1f} KB")
        with col3:
            st.metric("æ–‡ä»¶ç±»å‹", uploaded_file.type)
    
    @staticmethod
    def process_text_file(content: str, client: OpenAI, model: str, action: str):
        """å¤„ç†æ–‡æœ¬æ–‡ä»¶"""
        try:
            with st.spinner(f"æ­£åœ¨{action}æ–‡ä»¶å†…å®¹..."):
                if action == "æ€»ç»“":
                    prompt = f"è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹çš„ä¸»è¦è¦ç‚¹ï¼š\n\n{content[:4000]}"
                else:  # åˆ†æ
                    prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„ç»“æ„ã€ä¸»é¢˜å’Œå…³é”®ä¿¡æ¯ï¼š\n\n{content[:4000]}"
                
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0.7
                )
                
                result = response.choices[0].message.content
                
                st.markdown(f"#### ğŸ¯ {action}ç»“æœ")
                st.markdown(result)
                
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")


class ChatManager:
    """èŠå¤©ç®¡ç†å™¨"""
    
    @staticmethod
    def initialize_chat():
        """åˆå§‹åŒ–èŠå¤©"""
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "chat_count" not in st.session_state:
            st.session_state.chat_count = 0
    
    @staticmethod
    def show_welcome_message():
        """æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯"""
        if not st.session_state.messages:
            welcome_msg = """
            ğŸ‘‹ æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼
            
            æˆ‘å¯ä»¥å¸®æ‚¨ï¼š
            - ğŸ’¬ å›ç­”å„ç§é—®é¢˜
            - ğŸ“ æ–‡æœ¬åˆ†æå’Œæ€»ç»“
            - ğŸ” ä¿¡æ¯æŸ¥è¯¢å’Œè§£é‡Š
            - ğŸ’¡ åˆ›æ„å’Œå»ºè®®
            
            è¯·éšæ—¶å‘æˆ‘æé—®ï¼
            """
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
    
    @staticmethod
    def display_chat_history():
        """æ˜¾ç¤ºèŠå¤©å†å²"""
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    @staticmethod
    def process_user_input(client: OpenAI, model: str, prompt: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            try:
                with st.spinner("æ€è€ƒä¸­..."):
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": m["role"], "content": m["content"]} 
                            for m in st.session_state.messages[-10:]  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                        ],
                        max_tokens=1500,
                        temperature=0.7,
                        stream=True
                    )
                    
                    # æµå¼æ˜¾ç¤ºå›å¤
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    for chunk in response:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            response_placeholder.markdown(full_response + "â–Œ")
                    
                    response_placeholder.markdown(full_response)
                
                # æ·»åŠ AIå›å¤åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                st.session_state.chat_count += 1
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯: {e}"
                })
